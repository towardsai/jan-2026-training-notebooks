{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5FX9WHJj7Hz"
      },
      "source": [
        "# Lesson 5: Basic Workflow Patterns\n",
        "\n",
        "This notebook demonstrates AI agent workflow patterns using Google Gemini, focusing on chaining, routing, parallelization, and orchestration strategies.\n",
        "\n",
        "We will use the `google-genai` library to interact with Google's Gemini models.\n",
        "*Learning Objectives:\n",
        "\n",
        "1. Understand the issues with complex prompts that try to do everything at once.\n",
        "\n",
        "2. Learn how to code sequential workflows, i.e. breaking tasks into steps (generate questions → answer questions → find sources) for better consistency.\n",
        "\n",
        "3. Learn how to code parallel workflows, i.e. running tasks in parallel (answering questions in parallel) for higher speed.\n",
        "\n",
        "4. Learn how to code routing workflows, for example for classifying user intent and routing to specialized handlers (technical support, billing, general questions).\n",
        "\n",
        "5. Learn the orchestrator-worker pattern, which is a system where an orchestrator breaks complex queries into subtasks, specialized workers handle each task, and a synthesizer combines results into a cohesive response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROFh4KyZj7Hz"
      },
      "source": [
        "## 1. Setup\n",
        "\n",
        "### Set Up Python Environment\n",
        "\n",
        "Run the following command to install all the required packages to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkyepXBz6YXx"
      },
      "outputs": [],
      "source": [
        "%pip install -q \\\n",
        "  agentic-ai-engineering-course \\\n",
        "  google-auth==2.38.0 \\\n",
        "  opentelemetry-api==1.37.0 opentelemetry-sdk==1.37.0 \\\n",
        "  opentelemetry-exporter-otlp-proto-http==1.37.0 \\\n",
        "  opentelemetry-exporter-otlp-proto-common==1.37.0 \\\n",
        "  opentelemetry-proto==1.37.0 \\\n",
        "  jedi==0.18.2\n",
        "\n",
        "%pip check\n",
        "import IPython; IPython.Application.instance().kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configure Gemini API\n",
        "\n",
        "To configure the Gemini API, follow the step-by-step instructions from the `Course Admin` lesson.\n",
        "\n",
        "But here is a quick check on what you need to run this Notebook:\n",
        "\n",
        "1.  Get your key from [Google AI Studio](https://aistudio.google.com/app/apikey).\n",
        "\n",
        "2. In Google Colab, go to the \"Secrets\" tab (or the key icon) on the left-hand panel.\n",
        "\n",
        "3. Click \"Add new secret\" and create a new secret with the following details:\n",
        "\n",
        "    - Name: GOOGLE_API_KEY \n",
        "\n",
        "    - Value: Paste your API key here.\n",
        "\n",
        "4. Make sure to enable the option \"Notebook access\".\n",
        "\n",
        "Now, the code below will load the key from your Colab secrets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trying to load environment variables from `/Users/fabio/Desktop/course-ai-agents/.env`\n",
            "Environment variables loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "from utils import env\n",
        "\n",
        "env.load(required_env_vars=[\"GOOGLE_API_KEY\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Key Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLzh9oIZ32FP",
        "outputId": "e1809406-3986-4fc9-bdfa-5c2aa2ce64a3"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "from enum import Enum\n",
        "import random\n",
        "import time\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "from utils import pretty_print"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize the Gemini Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
          ]
        }
      ],
      "source": [
        "client = genai.Client()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Constants\n",
        "\n",
        "We will use the `gemini-2.5-flash` model, which is fast and cost-effective:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.5-flash\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQHYrdrETWE5"
      },
      "source": [
        "## 2. The Challenge with Complex Single LLM Calls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meM2RgTkj7H0"
      },
      "source": [
        "### Setting Up Mock Data\n",
        "\n",
        "We'll create three mock webpages about renewable energy topics that will serve as our source content for the FAQ generation examples. Each webpage has a title and detailed content about solar energy, wind turbines, and energy storage:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yD8-KVvjTbiI"
      },
      "outputs": [],
      "source": [
        "webpage_1 = {\n",
        "    \"title\": \"The Benefits of Solar Energy\",\n",
        "    \"content\": \"\"\"\n",
        "    Solar energy is a renewable powerhouse, offering numerous environmental and economic benefits.\n",
        "    By converting sunlight into electricity through photovoltaic (PV) panels, it reduces reliance on fossil fuels,\n",
        "    thereby cutting down greenhouse gas emissions. Homeowners who install solar panels can significantly\n",
        "    lower their monthly electricity bills, and in some cases, sell excess power back to the grid.\n",
        "    While the initial installation cost can be high, government incentives and long-term savings make\n",
        "    it a financially viable option for many. Solar power is also a key component in achieving energy\n",
        "    independence for nations worldwide.\n",
        "    \"\"\",\n",
        "}\n",
        "\n",
        "webpage_2 = {\n",
        "    \"title\": \"Understanding Wind Turbines\",\n",
        "    \"content\": \"\"\"\n",
        "    Wind turbines are towering structures that capture kinetic energy from the wind and convert it into\n",
        "    electrical power. They are a critical part of the global shift towards sustainable energy.\n",
        "    Turbines can be installed both onshore and offshore, with offshore wind farms generally producing more\n",
        "    consistent power due to stronger, more reliable winds. The main challenge for wind energy is its\n",
        "    intermittency—it only generates power when the wind blows. This necessitates the use of energy\n",
        "    storage solutions, like large-scale batteries, to ensure a steady supply of electricity.\n",
        "    \"\"\",\n",
        "}\n",
        "\n",
        "webpage_3 = {\n",
        "    \"title\": \"Energy Storage Solutions\",\n",
        "    \"content\": \"\"\"\n",
        "    Effective energy storage is the key to unlocking the full potential of renewable sources like solar\n",
        "    and wind. Because these sources are intermittent, storing excess energy when it's plentiful and\n",
        "    releasing it when it's needed is crucial for a stable power grid. The most common form of\n",
        "    large-scale storage is pumped-hydro storage, but battery technologies, particularly lithium-ion,\n",
        "    are rapidly becoming more affordable and widespread. These batteries can be used in homes, businesses,\n",
        "    and at the utility scale to balance energy supply and demand, making our energy system more\n",
        "    resilient and reliable.\n",
        "    \"\"\",\n",
        "}\n",
        "\n",
        "all_sources = [webpage_1, webpage_2, webpage_3]\n",
        "\n",
        "# We'll combine the content for the LLM to process\n",
        "combined_content = \"\\n\\n\".join(\n",
        "    [f\"Source Title: {source['title']}\\nContent: {source['content']}\" for source in all_sources]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtGkdMErj7H1"
      },
      "source": [
        "### Example: Complex Single LLM Call\n",
        "\n",
        "This example demonstrates the problem with trying to do everything in one complex prompt. We're asking the LLM to generate questions, find answers, and cite sources all in a single call, which can lead to inconsistent results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkGxJhhaTjBy",
        "outputId": "70df85d0-4bab-46bc-aad5-bbbc86fd6ba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[93m-------------------------- Complex prompt result (might be inconsistent) --------------------------\u001b[0m\n",
            "  {\n",
            "  \"question\": \"What is solar energy and how does it work?\",\n",
            "  \"answer\": \"Solar energy is a renewable powerhouse that converts sunlight into electricity through photovoltaic (PV) panels.\",\n",
            "  \"sources\": [\n",
            "    \"The Benefits of Solar Energy\"\n",
            "  ]\n",
            "}\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  {\n",
            "  \"question\": \"What are the environmental benefits of using solar energy?\",\n",
            "  \"answer\": \"Solar energy reduces reliance on fossil fuels, thereby cutting down greenhouse gas emissions.\",\n",
            "  \"sources\": [\n",
            "    \"The Benefits of Solar Energy\"\n",
            "  ]\n",
            "}\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  {\n",
            "  \"question\": \"How can solar energy benefit homeowners financially?\",\n",
            "  \"answer\": \"Homeowners who install solar panels can significantly lower their monthly electricity bills and, in some cases, sell excess power back to the grid.\",\n",
            "  \"sources\": [\n",
            "    \"The Benefits of Solar Energy\"\n",
            "  ]\n",
            "}\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  {\n",
            "  \"question\": \"Is solar energy a financially viable option despite initial costs?\",\n",
            "  \"answer\": \"While the initial installation cost can be high, government incentives and long-term savings make it a financially viable option for many.\",\n",
            "  \"sources\": [\n",
            "    \"The Benefits of Solar Energy\"\n",
            "  ]\n",
            "}\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  {\n",
            "  \"question\": \"What are wind turbines and what do they do?\",\n",
            "  \"answer\": \"Wind turbines are towering structures that capture kinetic energy from the wind and convert it into electrical power.\",\n",
            "  \"sources\": [\n",
            "    \"Understanding Wind Turbines\"\n",
            "  ]\n",
            "}\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  {\n",
            "  \"question\": \"Where can wind turbines be installed?\",\n",
            "  \"answer\": \"Wind turbines can be installed both onshore and offshore, with offshore wind farms generally producing more consistent power due to stronger, more reliable winds.\",\n",
            "  \"sources\": [\n",
            "    \"Understanding Wind Turbines\"\n",
            "  ]\n",
            "}\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  {\n",
            "  \"question\": \"What is the main challenge associated with wind energy?\",\n",
            "  \"answer\": \"The main challenge for wind energy is its intermittency, meaning it only generates power when the wind blows.\",\n",
            "  \"sources\": [\n",
            "    \"Understanding Wind Turbines\"\n",
            "  ]\n",
            "}\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  {\n",
            "  \"question\": \"Why is energy storage crucial for renewable energy sources like solar and wind?\",\n",
            "  \"answer\": \"Effective energy storage is key to unlocking the full potential of renewable sources because it allows storing excess energy when plentiful and releasing it when needed, which is crucial for a stable power grid.\",\n",
            "  \"sources\": [\n",
            "    \"Energy Storage Solutions\",\n",
            "    \"Understanding Wind Turbines\"\n",
            "  ]\n",
            "}\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  {\n",
            "  \"question\": \"What are some common forms of large-scale energy storage?\",\n",
            "  \"answer\": \"The most common form of large-scale storage is pumped-hydro storage, but battery technologies, particularly lithium-ion, are rapidly becoming more affordable and widespread.\",\n",
            "  \"sources\": [\n",
            "    \"Energy Storage Solutions\"\n",
            "  ]\n",
            "}\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  {\n",
            "  \"question\": \"How do battery technologies improve the energy system?\",\n",
            "  \"answer\": \"Battery technologies can be used in homes, businesses, and at the utility scale to balance energy supply and demand, making our energy system more resilient and reliable.\",\n",
            "  \"sources\": [\n",
            "    \"Energy Storage Solutions\"\n",
            "  ]\n",
            "}\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# This prompt tries to do everything at once: generate questions, find answers,\n",
        "# and cite sources. This complexity can often confuse the model.\n",
        "n_questions = 10\n",
        "prompt_complex = f\"\"\"\n",
        "Based on the provided content from three webpages, generate a list of exactly {n_questions} frequently asked questions (FAQs).\n",
        "For each question, provide a concise answer derived ONLY from the text.\n",
        "After each answer, you MUST include a list of the 'Source Title's that were used to formulate that answer.\n",
        "\n",
        "<provided_content>\n",
        "{combined_content}\n",
        "</provided_content>\n",
        "\"\"\".strip()\n",
        "\n",
        "# Pydantic classes for structured outputs\n",
        "class FAQ(BaseModel):\n",
        "    \"\"\"A FAQ is a question and answer pair, with a list of sources used to answer the question.\"\"\"\n",
        "    question: str = Field(description=\"The question to be answered\")\n",
        "    answer: str = Field(description=\"The answer to the question\")\n",
        "    sources: list[str] = Field(description=\"The sources used to answer the question\")\n",
        "\n",
        "class FAQList(BaseModel):\n",
        "    \"\"\"A list of FAQs\"\"\"\n",
        "    faqs: list[FAQ] = Field(description=\"A list of FAQs\")\n",
        "\n",
        "# Generate FAQs\n",
        "config = types.GenerateContentConfig(\n",
        "    response_mime_type=\"application/json\",\n",
        "    response_schema=FAQList\n",
        ")\n",
        "response_complex = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt_complex,\n",
        "    config=config\n",
        ")\n",
        "result_complex = response_complex.parsed\n",
        "\n",
        "pretty_print.wrapped(\n",
        "    text=[faq.model_dump_json(indent=2) for faq in result_complex.faqs],\n",
        "    title=\"Complex prompt result (might be inconsistent)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ0GxwEK4RVR"
      },
      "source": [
        "## 3. Building a Sequential Workflow: FAQ Generation Pipeline\n",
        "\n",
        "Now, let's split the complex prompt above into a chain of simpler prompts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsKbKIbBj7H1"
      },
      "source": [
        "### Question Generation Function\n",
        "\n",
        "Let's create a function to generate questions from the content. This step focuses solely on creating relevant questions based on the provided material:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WET69j1c4clg",
        "outputId": "25655c61-24b6-4cf0-daf5-2334a6abd411"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[93m-------------------------------------------- Questions --------------------------------------------\u001b[0m\n",
            "  What are the primary environmental and economic benefits of solar energy?\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  How do homeowners financially benefit from installing solar panels?\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  What is the main process by which wind turbines generate electricity?\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  What is the primary challenge of wind energy, and how is it addressed?\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  Why is effective energy storage crucial for renewable energy sources like solar and wind?\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  What are some common large-scale energy storage methods mentioned?\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  Are there government incentives available for solar panel installation?\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  What is the difference in power consistency between onshore and offshore wind farms?\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  How do energy storage solutions make the energy system more resilient and reliable?\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  Can excess solar power generated by homeowners be sold back to the grid?\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "class QuestionList(BaseModel):\n",
        "    \"\"\"A list of questions\"\"\"\n",
        "    questions: list[str] = Field(description=\"A list of questions\")\n",
        "\n",
        "prompt_generate_questions = \"\"\"\n",
        "Based on the content below, generate a list of {n_questions} relevant and distinct questions that a user might have.\n",
        "\n",
        "<provided_content>\n",
        "{combined_content}\n",
        "</provided_content>\n",
        "\"\"\".strip()\n",
        "\n",
        "def generate_questions(content: str, n_questions: int = 10) -> list[str]:\n",
        "    \"\"\"\n",
        "    Generate a list of questions based on the provided content.\n",
        "\n",
        "    Args:\n",
        "        content: The combined content from all sources\n",
        "\n",
        "    Returns:\n",
        "        list: A list of generated questions\n",
        "    \"\"\"\n",
        "    config = types.GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=QuestionList\n",
        "    )\n",
        "    response_questions = client.models.generate_content(\n",
        "        model=MODEL_ID,\n",
        "        contents=prompt_generate_questions.format(n_questions=n_questions, combined_content=content),\n",
        "        config=config\n",
        "    )\n",
        "\n",
        "    return response_questions.parsed.questions\n",
        "\n",
        "# Test the question generation function\n",
        "questions = generate_questions(combined_content, n_questions=10)\n",
        "\n",
        "pretty_print.wrapped(\n",
        "    questions,\n",
        "    title=\"Questions\",\n",
        "    header_color=pretty_print.Color.YELLOW\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCoQfR3vj7H1"
      },
      "source": [
        "### Answer Generation Function\n",
        "\n",
        "Next, we create a function to generate answers for individual questions using only the provided content:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVXKXFl6j7H1",
        "outputId": "8316b365-a8bd-45b3-fc83-9216b1e5ebc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[93m--------------------------------------------- Question ---------------------------------------------\u001b[0m\n",
            "  What are the primary environmental and economic benefits of solar energy?\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[92m---------------------------------------------- Answer ----------------------------------------------\u001b[0m\n",
            "  The primary environmental benefit of solar energy is cutting down greenhouse gas emissions by reducing reliance on fossil fuels. Economically, it allows homeowners to significantly lower their monthly electricity bills and potentially sell excess power back to the grid.\n",
            "\u001b[92m----------------------------------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "prompt_answer_question = \"\"\"\n",
        "Using ONLY the provided content below, answer the following question.\n",
        "The answer should be concise and directly address the question.\n",
        "\n",
        "<question>\n",
        "{question}\n",
        "</question>\n",
        "\n",
        "<provided_content>\n",
        "{combined_content}\n",
        "</provided_content>\n",
        "\"\"\".strip()\n",
        "\n",
        "def answer_question(question: str, content: str) -> str:\n",
        "    \"\"\"\n",
        "    Generate an answer for a specific question using only the provided content.\n",
        "\n",
        "    Args:\n",
        "        question: The question to answer\n",
        "        content: The combined content from all sources\n",
        "\n",
        "    Returns:\n",
        "        str: The generated answer\n",
        "    \"\"\"\n",
        "    answer_response = client.models.generate_content(\n",
        "        model=MODEL_ID,\n",
        "        contents=prompt_answer_question.format(question=question, combined_content=content),\n",
        "    )\n",
        "    return answer_response.text\n",
        "\n",
        "# Test the answer generation function\n",
        "test_question = questions[0]\n",
        "test_answer = answer_question(test_question, combined_content)\n",
        "pretty_print.wrapped(test_question, title=\"Question\", header_color=pretty_print.Color.YELLOW)\n",
        "pretty_print.wrapped(test_answer, title=\"Answer\", header_color=pretty_print.Color.GREEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddYTqf7Vj7H1"
      },
      "source": [
        "### Source Finding Function\n",
        "\n",
        "Finally, we create a function to identify which sources were used to generate an answer:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyApKT-hj7H1",
        "outputId": "aeed549e-0f50-4876-9315-602795c3f211"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[93m--------------------------------------------- Question ---------------------------------------------\u001b[0m\n",
            "  What are the primary environmental and economic benefits of solar energy?\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[92m---------------------------------------------- Answer ----------------------------------------------\u001b[0m\n",
            "  The primary environmental benefit of solar energy is cutting down greenhouse gas emissions by reducing reliance on fossil fuels. Economically, it allows homeowners to significantly lower their monthly electricity bills and potentially sell excess power back to the grid.\n",
            "\u001b[92m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[96m--------------------------------------------- Sources ---------------------------------------------\u001b[0m\n",
            "  The Benefits of Solar Energy\n",
            "\u001b[96m----------------------------------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "class SourceList(BaseModel):\n",
        "    \"\"\"A list of source titles that were used to answer the question\"\"\"\n",
        "    sources: list[str] = Field(description=\"A list of source titles that were used to answer the question\")\n",
        "\n",
        "prompt_find_sources = \"\"\"\n",
        "You will be given a question and an answer that was generated from a set of documents.\n",
        "Your task is to identify which of the original documents were used to create the answer.\n",
        "\n",
        "<question>\n",
        "{question}\n",
        "</question>\n",
        "\n",
        "<answer>\n",
        "{answer}\n",
        "</answer>\n",
        "\n",
        "<provided_content>\n",
        "{combined_content}\n",
        "</provided_content>\n",
        "\"\"\".strip()\n",
        "\n",
        "def find_sources(question: str, answer: str, content: str) -> list[str]:\n",
        "    \"\"\"\n",
        "    Identify which sources were used to generate an answer.\n",
        "\n",
        "    Args:\n",
        "        question: The original question\n",
        "        answer: The generated answer\n",
        "        content: The combined content from all sources\n",
        "\n",
        "    Returns:\n",
        "        list: A list of source titles that were used\n",
        "    \"\"\"\n",
        "    config = types.GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=SourceList\n",
        "    )\n",
        "    sources_response = client.models.generate_content(\n",
        "        model=MODEL_ID,\n",
        "        contents=prompt_find_sources.format(question=question, answer=answer, combined_content=content),\n",
        "        config=config\n",
        "    )\n",
        "    return sources_response.parsed.sources\n",
        "\n",
        "# Test the source finding function\n",
        "test_sources = find_sources(test_question, test_answer, combined_content)\n",
        "pretty_print.wrapped(test_question, title=\"Question\", header_color=pretty_print.Color.YELLOW)\n",
        "pretty_print.wrapped(test_answer, title=\"Answer\", header_color=pretty_print.Color.GREEN)\n",
        "pretty_print.wrapped(test_sources, title=\"Sources\", header_color=pretty_print.Color.CYAN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Illuwizvj7H1"
      },
      "source": [
        "### Executing the Sequential Workflow\n",
        "\n",
        "Now we combine all three functions into a sequential workflow: Generate Questions → Answer Questions → Find Sources. Each step is executed one after another for each question. Notice how much time it takes to run the full workflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rd7ZpDij7H1",
        "outputId": "896e0ea6-de15-42ac-8aab-38b68b6adf55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential processing completed in 22.20 seconds\n",
            "\u001b[93m--------------------------------------- Sequential FAQ List ---------------------------------------\u001b[0m\n",
            "  {\n",
            "  \"question\": \"What are the primary financial benefits of installing solar panels for homeowners, and are there any initial costs to consider?\",\n",
            "  \"answer\": \"The primary financial benefits of installing solar panels for homeowners are significantly lowered monthly electricity bills and, in some cases, the ability to sell excess power back to the grid. The initial installation cost can be high.\",\n",
            "  \"sources\": [\n",
            "    \"The Benefits of Solar Energy\"\n",
            "  ]\n",
            "}\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  {\n",
            "  \"question\": \"What are the main differences between onshore and offshore wind farms, and what is the biggest challenge associated with wind energy generation?\",\n",
            "  \"answer\": \"Offshore wind farms generally produce more consistent power than onshore wind farms due to stronger, more reliable winds. The biggest challenge associated with wind energy generation is its intermittency, as it only generates power when the wind blows.\",\n",
            "  \"sources\": [\n",
            "    \"Understanding Wind Turbines\"\n",
            "  ]\n",
            "}\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  {\n",
            "  \"question\": \"Why is energy storage essential for renewable energy sources like solar and wind, and what are the common types of large-scale storage solutions?\",\n",
            "  \"answer\": \"Energy storage is essential for renewable sources like solar and wind because these sources are intermittent, meaning they only generate power when conditions are favorable (e.g., when the sun shines or the wind blows). Storing excess energy when it's plentiful and releasing it when needed is crucial for ensuring a stable and steady supply of electricity and unlocking their full potential for a stable power grid.\\n\\nCommon types of large-scale storage solutions include pumped-hydro storage and battery technologies, particularly lithium-ion.\",\n",
            "  \"sources\": [\n",
            "    \"Understanding Wind Turbines\",\n",
            "    \"Energy Storage Solutions\"\n",
            "  ]\n",
            "}\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  {\n",
            "  \"question\": \"How do energy storage solutions address the intermittency challenges of renewable energy sources such as solar and wind?\",\n",
            "  \"answer\": \"Energy storage solutions address the intermittency challenges of renewable energy sources like solar and wind by storing excess energy when these sources are plentiful and releasing it when it's needed, thus ensuring a steady supply of electricity and balancing energy supply and demand.\",\n",
            "  \"sources\": [\n",
            "    \"Understanding Wind Turbines\",\n",
            "    \"Energy Storage Solutions\"\n",
            "  ]\n",
            "}\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "def sequential_workflow(content, n_questions=10) -> list[FAQ]:\n",
        "    \"\"\"\n",
        "    Execute the complete sequential workflow for FAQ generation.\n",
        "\n",
        "    Args:\n",
        "        content: The combined content from all sources\n",
        "\n",
        "    Returns:\n",
        "        list: A list of FAQs with questions, answers, and sources\n",
        "    \"\"\"\n",
        "    # Generate questions\n",
        "    questions = generate_questions(content, n_questions)\n",
        "\n",
        "    # Answer and find sources for each question sequentially\n",
        "    final_faqs = []\n",
        "    for question in questions:\n",
        "        # Generate an answer for the current question\n",
        "        answer = answer_question(question, content)\n",
        "\n",
        "        # Identify the sources for the generated answer\n",
        "        sources = find_sources(question, answer, content)\n",
        "\n",
        "        faq = FAQ(\n",
        "            question=question,\n",
        "            answer=answer,\n",
        "            sources=sources\n",
        "        )\n",
        "        final_faqs.append(faq)\n",
        "\n",
        "    return final_faqs\n",
        "\n",
        "# Execute the sequential workflow (measure time for comparison)\n",
        "start_time = time.monotonic()\n",
        "sequential_faqs = sequential_workflow(combined_content, n_questions=4)\n",
        "end_time = time.monotonic()\n",
        "print(f\"Sequential processing completed in {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Display the final result\n",
        "pretty_print.wrapped(\n",
        "    [faq.model_dump_json(indent=2) for faq in sequential_faqs],\n",
        "    title=\"Sequential FAQ List\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps92Komdj7H2"
      },
      "source": [
        "## 4. Optimizing Sequential Workflows With Parallel Processing\n",
        "\n",
        "While the sequential workflow works well, we can optimize it by running some steps in parallel. We can generate the answer and find sources simultaneously for all the questions. This can significantly reduce the overall processing time.\n",
        "\n",
        "**Important**: you may meet the rate limits of your account if you do this for a lot of questions. If you go over your rate limits, the API calls will return errors and retry after a timeout. Make sure to take this into account when building real-world products!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Implementing Parallel Processing\n",
        "\n",
        "Let's implement a parallel version of our workflow using Python's `asyncio` library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rlbe82L9j7H2"
      },
      "outputs": [],
      "source": [
        "async def answer_question_async(question: str, content: str) -> str:\n",
        "    \"\"\"\n",
        "    Async version of answer_question function.\n",
        "    \"\"\"\n",
        "    prompt = prompt_answer_question.format(question=question, combined_content=content)\n",
        "    response = await client.aio.models.generate_content(\n",
        "        model=MODEL_ID,\n",
        "        contents=prompt\n",
        "    )\n",
        "    return response.text\n",
        "\n",
        "async def find_sources_async(question: str, answer: str, content: str) -> list[str]:\n",
        "    \"\"\"\n",
        "    Async version of find_sources function.\n",
        "    \"\"\"\n",
        "    prompt = prompt_find_sources.format(question=question, answer=answer, combined_content=content)\n",
        "    config = types.GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=SourceList\n",
        "    )\n",
        "    response = await client.aio.models.generate_content(\n",
        "        model=MODEL_ID,\n",
        "        contents=prompt,\n",
        "        config=config\n",
        "    )\n",
        "    return response.parsed.sources\n",
        "\n",
        "async def process_question_parallel(question: str, content: str) -> FAQ:\n",
        "    \"\"\"\n",
        "    Process a single question by generating answer and finding sources in parallel.\n",
        "    \"\"\"\n",
        "    answer = await answer_question_async(question, content)\n",
        "    sources = await find_sources_async(question, answer, content)\n",
        "    return FAQ(\n",
        "        question=question,\n",
        "        answer=answer,\n",
        "        sources=sources\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeDiQIBVj7H2"
      },
      "source": [
        "### Executing the Parallel Workflow\n",
        "\n",
        "Now let's process all questions using parallel execution. We'll process multiple questions concurrently, which can significantly reduce the total processing time. Notice how much time it takes to run the full workflow and compare it with the execution time of the sequential workflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE5Zjuxyj7H2",
        "outputId": "e140ce81-a441-4c23-b245-be5210ac2041"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parallel processing completed in 8.98 seconds\n",
            "\u001b[93m---------------------------------- Generated FAQ List (Parallel) ----------------------------------\u001b[0m\n",
            "  {\n",
            "  \"question\": \"What are the primary environmental and economic benefits of using solar energy?\",\n",
            "  \"answer\": \"The primary environmental benefit of solar energy is cutting down greenhouse gas emissions by reducing reliance on fossil fuels.\\n\\nThe primary economic benefits include significantly lower monthly electricity bills, the ability to sell excess power back to the grid, long-term savings, and contributing to energy independence for nations.\",\n",
            "  \"sources\": [\n",
            "    \"The Benefits of Solar Energy\"\n",
            "  ]\n",
            "}\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  {\n",
            "  \"question\": \"How do wind turbines generate electricity, and what are the main challenges associated with wind power?\",\n",
            "  \"answer\": \"Wind turbines generate electricity by capturing kinetic energy from the wind and converting it into electrical power. The main challenge associated with wind power is its intermittency, as it only generates power when the wind blows.\",\n",
            "  \"sources\": [\n",
            "    \"Understanding Wind Turbines\"\n",
            "  ]\n",
            "}\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  {\n",
            "  \"question\": \"Why is energy storage crucial for renewable sources like solar and wind, and what are the common large-scale storage technologies?\",\n",
            "  \"answer\": \"Energy storage is crucial for renewable sources like solar and wind because these sources are intermittent, meaning they only generate power when conditions are right (e.g., when the sun shines or the wind blows). Storing excess energy when it's plentiful and releasing it when needed ensures a steady supply of electricity and a stable power grid.\\n\\nThe common large-scale storage technologies mentioned are pumped-hydro storage and battery technologies, particularly lithium-ion.\",\n",
            "  \"sources\": [\n",
            "    \"Understanding Wind Turbines\",\n",
            "    \"Energy Storage Solutions\"\n",
            "  ]\n",
            "}\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "  {\n",
            "  \"question\": \"How do government incentives impact the financial viability of installing solar panels, given the initial high costs?\",\n",
            "  \"answer\": \"Government incentives make installing solar panels a financially viable option, despite the initial high costs.\",\n",
            "  \"sources\": [\n",
            "    \"The Benefits of Solar Energy\"\n",
            "  ]\n",
            "}\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "async def parallel_workflow(content: str, n_questions: int = 10) -> list[FAQ]:\n",
        "    \"\"\"\n",
        "    Execute the complete parallel workflow for FAQ generation.\n",
        "\n",
        "    Args:\n",
        "        content: The combined content from all sources\n",
        "\n",
        "    Returns:\n",
        "        list: A list of FAQs with questions, answers, and sources\n",
        "    \"\"\"\n",
        "    # Generate questions (this step remains synchronous)\n",
        "    questions = generate_questions(content, n_questions)\n",
        "\n",
        "    # Process all questions in parallel\n",
        "    tasks = [process_question_parallel(question, content) for question in questions]\n",
        "    parallel_faqs = await asyncio.gather(*tasks)\n",
        "\n",
        "    return parallel_faqs\n",
        "\n",
        "# Execute the parallel workflow (measure time for comparison)\n",
        "start_time = time.monotonic()\n",
        "parallel_faqs = await parallel_workflow(combined_content, n_questions=4)\n",
        "end_time = time.monotonic()\n",
        "print(f\"Parallel processing completed in {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Display the final result\n",
        "pretty_print.wrapped(\n",
        "    text=[faq.model_dump_json(indent=2) for faq in parallel_faqs],\n",
        "    title=\"Generated FAQ List (Parallel)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYcKmZVfj7H2"
      },
      "source": [
        "### Sequential vs Parallel: Key Differences\n",
        "\n",
        "The main differences between sequential and parallel approaches:\n",
        "\n",
        "**Sequential Processing:**\n",
        "- Questions are processed one at a time\n",
        "- Predictable execution order\n",
        "- Easier to debug and understand\n",
        "- Higher total processing time\n",
        "\n",
        "**Parallel Processing:**\n",
        "- Multiple questions can be processed simultaneously\n",
        "- Significant reduction in total processing time\n",
        "- More complex error handling\n",
        "- Better resource utilization\n",
        "\n",
        "Both approaches produce the same results, but parallel processing can be significantly faster for larger datasets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKJAjzbk4oMC"
      },
      "source": [
        "## 5. Building a Basic Routing Workflow\n",
        "\n",
        "Routing is a method that categorizes an input and then sends it to a specific task designed to handle that type of input. This approach helps keep different functions separate and lets you create more specialized prompts. If you don't use routing, trying to optimize for one kind of input might negatively affect how well the system performs with other kinds of inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0EZ8uunj7H2"
      },
      "source": [
        "### Intent Classification\n",
        "\n",
        "First, we create a classification prompt and function to determine the user's intent. This will help us route the query to the appropriate handler:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS8GDHYs47En",
        "outputId": "99b9522c-2bd4-4d0c-82d7-a67eed9ee4f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[93m-------------------------------------------- Question 1 --------------------------------------------\u001b[0m\n",
            "  My internet connection is not working.\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[95m--------------------------------------------- Intent 1 ---------------------------------------------\u001b[0m\n",
            "  IntentEnum.TECHNICAL_SUPPORT\n",
            "\u001b[95m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\n",
            "\u001b[93m-------------------------------------------- Question 2 --------------------------------------------\u001b[0m\n",
            "  I think there is a mistake on my last invoice.\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[95m--------------------------------------------- Intent 2 ---------------------------------------------\u001b[0m\n",
            "  IntentEnum.BILLING_INQUIRY\n",
            "\u001b[95m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\n",
            "\u001b[93m-------------------------------------------- Question 3 --------------------------------------------\u001b[0m\n",
            "  What are your opening hours?\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[95m--------------------------------------------- Intent 3 ---------------------------------------------\u001b[0m\n",
            "  IntentEnum.GENERAL_QUESTION\n",
            "\u001b[95m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class IntentEnum(str, Enum):\n",
        "    \"\"\"\n",
        "    Defines the allowed values for the 'intent' field.\n",
        "    Inheriting from 'str' ensures that the values are treated as strings.\n",
        "    \"\"\"\n",
        "    TECHNICAL_SUPPORT = \"Technical Support\"\n",
        "    BILLING_INQUIRY = \"Billing Inquiry\"\n",
        "    GENERAL_QUESTION = \"General Question\"\n",
        "\n",
        "class UserIntent(BaseModel):\n",
        "    \"\"\"\n",
        "    Defines the expected response schema for the intent classification.\n",
        "    \"\"\"\n",
        "    intent: IntentEnum = Field(description=\"The intent of the user's query\")\n",
        "\n",
        "prompt_classification = \"\"\"\n",
        "Classify the user's query into one of the following categories.\n",
        "\n",
        "<categories>\n",
        "{categories}\n",
        "</categories>\n",
        "\n",
        "<user_query>\n",
        "{user_query}\n",
        "</user_query>\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "def classify_intent(user_query: str) -> IntentEnum:\n",
        "    \"\"\"Uses an LLM to classify a user query.\"\"\"\n",
        "    prompt = prompt_classification.format(\n",
        "        user_query=user_query,\n",
        "        categories=[intent.value for intent in IntentEnum]\n",
        "    )\n",
        "    config = types.GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=UserIntent\n",
        "    )\n",
        "    response = client.models.generate_content(\n",
        "        model=MODEL_ID,\n",
        "        contents=prompt,\n",
        "        config=config\n",
        "    )\n",
        "    return response.parsed.intent\n",
        "\n",
        "\n",
        "query_1 = \"My internet connection is not working.\"\n",
        "query_2 = \"I think there is a mistake on my last invoice.\"\n",
        "query_3 = \"What are your opening hours?\"\n",
        "\n",
        "intent_1 = classify_intent(query_1)\n",
        "intent_2 = classify_intent(query_2)\n",
        "intent_3 = classify_intent(query_3)\n",
        "\n",
        "# Print the results\n",
        "queries = [query_1, query_2, query_3]\n",
        "intents = [intent_1, intent_2, intent_3]\n",
        "for i, (query, intent) in enumerate(zip(queries, intents), start=1):\n",
        "    pretty_print.wrapped(\n",
        "        text=query,\n",
        "        title=f\"Question {i}\"\n",
        "    )\n",
        "    pretty_print.wrapped(\n",
        "        text=intent,\n",
        "        title=f\"Intent {i}\",\n",
        "        header_color=pretty_print.Color.MAGENTA\n",
        "    )\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0ob6fP5j7H2"
      },
      "source": [
        "### Defining Specialized Handlers\n",
        "\n",
        "Next, we create specialized prompts for each type of query and a routing function that directs queries to the appropriate handler based on the classified intent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WBkXZP15f3Z",
        "outputId": "e7c05956-d9ad-4d13-db4c-0cdd62d07e5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[93m-------------------------------------------- Question 1 --------------------------------------------\u001b[0m\n",
            "  My internet connection is not working.\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[95m--------------------------------------------- Intent 1 ---------------------------------------------\u001b[0m\n",
            "  IntentEnum.TECHNICAL_SUPPORT\n",
            "\u001b[95m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[92m-------------------------------------------- Response 1 --------------------------------------------\u001b[0m\n",
            "  Hello there! I'm sorry to hear you're having trouble with your internet connection. That can definitely be frustrating.\n",
            "\n",
            "To help me understand what's going on and assist you best, could you please provide a few more details?\n",
            "\n",
            "1.  **What exactly are you experiencing?** For example, are you not seeing your Wi-Fi network, is your Wi-Fi connected but no websites are loading, or are there any specific error messages?\n",
            "2.  **What device are you trying to connect with?** (e.g., a laptop, phone, desktop PC)\n",
            "3.  **Have you already tried any troubleshooting steps yourself?** For instance, have you tried:\n",
            "    *   Restarting your computer or device?\n",
            "    *   Restarting your Wi-Fi router and modem (unplugging them for 30 seconds and plugging them back in)?\n",
            "    *   Checking if other devices can connect to the internet?\n",
            "\n",
            "Once I have a bit more information, I'll be happy to guide you through some potential solutions.\n",
            "\u001b[92m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\n",
            "\u001b[93m-------------------------------------------- Question 2 --------------------------------------------\u001b[0m\n",
            "  I think there is a mistake on my last invoice.\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[95m--------------------------------------------- Intent 2 ---------------------------------------------\u001b[0m\n",
            "  IntentEnum.BILLING_INQUIRY\n",
            "\u001b[95m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[92m-------------------------------------------- Response 2 --------------------------------------------\u001b[0m\n",
            "  I'm sorry to hear you think there might be a mistake on your last invoice. I can definitely help you look into that!\n",
            "\n",
            "To access your account and investigate the charges, could you please provide your account number?\n",
            "\u001b[92m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\n",
            "\u001b[93m-------------------------------------------- Question 3 --------------------------------------------\u001b[0m\n",
            "  What are your opening hours?\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[95m--------------------------------------------- Intent 3 ---------------------------------------------\u001b[0m\n",
            "  IntentEnum.GENERAL_QUESTION\n",
            "\u001b[95m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[92m-------------------------------------------- Response 3 --------------------------------------------\u001b[0m\n",
            "  I apologize, but I'm not sure how to help with that. As an AI, I don't have a physical location or opening hours.\n",
            "\u001b[92m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt_technical_support = \"\"\"\n",
        "You are a helpful technical support agent.\n",
        "\n",
        "Here's the user's query:\n",
        "<user_query>\n",
        "{user_query}\n",
        "</user_query>\n",
        "\n",
        "Provide a helpful first response, asking for more details like what troubleshooting steps they have already tried.\n",
        "\"\"\".strip()\n",
        "\n",
        "prompt_billing_inquiry = \"\"\"\n",
        "You are a helpful billing support agent.\n",
        "\n",
        "Here's the user's query:\n",
        "<user_query>\n",
        "{user_query}\n",
        "</user_query>\n",
        "\n",
        "Acknowledge their concern and inform them that you will need to look up their account, asking for their account number.\n",
        "\"\"\".strip()\n",
        "\n",
        "prompt_general_question = \"\"\"\n",
        "You are a general assistant.\n",
        "\n",
        "Here's the user's query:\n",
        "<user_query>\n",
        "{user_query}\n",
        "</user_query>\n",
        "\n",
        "Apologize that you are not sure how to help.\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "def handle_query(user_query: str, intent: str) -> str:\n",
        "    \"\"\"Routes a query to the correct handler based on its classified intent.\"\"\"\n",
        "    if intent == IntentEnum.TECHNICAL_SUPPORT:\n",
        "        prompt = prompt_technical_support.format(user_query=user_query)\n",
        "    elif intent == IntentEnum.BILLING_INQUIRY:\n",
        "        prompt = prompt_billing_inquiry.format(user_query=user_query)\n",
        "    elif intent == IntentEnum.GENERAL_QUESTION:\n",
        "        prompt = prompt_general_question.format(user_query=user_query)\n",
        "    else:\n",
        "        prompt = prompt_general_question.format(user_query=user_query)\n",
        "    response = client.models.generate_content(\n",
        "        model=MODEL_ID,\n",
        "        contents=prompt\n",
        "    )\n",
        "    return response.text\n",
        "\n",
        "\n",
        "response_1 = handle_query(query_1, intent_1)\n",
        "response_2 = handle_query(query_2, intent_2)\n",
        "response_3 = handle_query(query_3, intent_3)\n",
        "\n",
        "# Print the results\n",
        "queries = [query_1, query_2, query_3]\n",
        "intents = [intent_1, intent_2, intent_3]\n",
        "responses = [response_1, response_2, response_3]\n",
        "for i, (query, intent, response) in enumerate(zip(queries, intents, responses), start=1):\n",
        "    pretty_print.wrapped(\n",
        "        text=query,\n",
        "        title=f\"Question {i}\"\n",
        "    )\n",
        "    pretty_print.wrapped(\n",
        "        text=intent,\n",
        "        title=f\"Intent {i}\",\n",
        "        header_color=pretty_print.Color.MAGENTA\n",
        "    )\n",
        "    pretty_print.wrapped(\n",
        "        text=response,\n",
        "        title=f\"Response {i}\",\n",
        "        header_color=pretty_print.Color.GREEN\n",
        "    )\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j7Eg9GC5gaD"
      },
      "source": [
        "## 6. Orchestrator-Worker Pattern: Dynamic Task Decomposition\n",
        "\n",
        "The orchestrator-workers workflow uses a main LLM to dynamically break down complex tasks into smaller subtasks, which are then assigned to other \"worker\" LLMs. The orchestrator LLM also combines the results from these workers.\n",
        "\n",
        "This approach is ideal for complex problems where the specific steps or subtasks can't be known in advance. For instance, in a coding project, the orchestrator can decide which files need modifying and how, based on the initial request. While it might look similar to parallel processing, its key advantage is flexibility: instead of pre-defined subtasks, the orchestrator LLM determines them on the fly according to the given input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA9H_2t4j7H2"
      },
      "source": [
        "### Defining the Orchestrator\n",
        "\n",
        "The orchestrator is the central coordinator that breaks down complex user queries into structured JSON tasks. It analyzes the input and identifies what types of actions need to be taken, such as billing inquiries, product returns, or status updates:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mwUdpaYqX4BH"
      },
      "outputs": [],
      "source": [
        "class QueryTypeEnum(str, Enum):\n",
        "    \"\"\"The type of query to be handled.\"\"\"\n",
        "    BILLING_INQUIRY = \"BillingInquiry\"\n",
        "    PRODUCT_RETURN = \"ProductReturn\"\n",
        "    STATUS_UPDATE = \"StatusUpdate\"\n",
        "\n",
        "class Task(BaseModel):\n",
        "    \"\"\"A task to be performed.\"\"\"\n",
        "    query_type: QueryTypeEnum = Field(description=\"The type of query to be handled.\")\n",
        "    invoice_number: str | None = Field(description=\"The invoice number to be used for the billing inquiry.\", default=None)\n",
        "    product_name: str | None = Field(description=\"The name of the product to be returned.\", default=None)\n",
        "    reason_for_return: str | None = Field(description=\"The reason for returning the product.\", default=None)\n",
        "    order_id: str | None = Field(description=\"The order ID to be used for the status update.\", default=None)\n",
        "\n",
        "class TaskList(BaseModel):\n",
        "    \"\"\"A list of tasks to be performed.\"\"\"\n",
        "    tasks: list[Task] = Field(description=\"A list of tasks to be performed.\")\n",
        "\n",
        "prompt_orchestrator = f\"\"\"\n",
        "You are a master orchestrator. Your job is to break down a complex user query into a list of sub-tasks.\n",
        "Each sub-task must have a \"query_type\" and its necessary parameters.\n",
        "\n",
        "The possible \"query_type\" values and their required parameters are:\n",
        "1. \"{QueryTypeEnum.BILLING_INQUIRY.value}\": Requires \"invoice_number\".\n",
        "2. \"{QueryTypeEnum.PRODUCT_RETURN.value}\": Requires \"product_name\" and \"reason_for_return\".\n",
        "3. \"{QueryTypeEnum.STATUS_UPDATE.value}\": Requires \"order_id\".\n",
        "\n",
        "Here's the user's query.\n",
        "\n",
        "<user_query>\n",
        "{{query}}\n",
        "</user_query>\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "def orchestrator(query: str) -> list[Task]:\n",
        "    \"\"\"Breaks down a complex query into a list of tasks.\"\"\"\n",
        "    prompt = prompt_orchestrator.format(query=query)\n",
        "    config = types.GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=TaskList\n",
        "    )\n",
        "    response = client.models.generate_content(\n",
        "        model=MODEL_ID,\n",
        "        contents=prompt,\n",
        "        config=config\n",
        "    )\n",
        "    return response.parsed.tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQLWg2jZj7H2"
      },
      "source": [
        "### Billing Worker Implementation\n",
        "\n",
        "The billing worker specializes in handling invoice-related inquiries. It extracts the specific concern from the user's query, simulates opening an investigation, and returns structured information about the action taken:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "od132EoqX6MU"
      },
      "outputs": [],
      "source": [
        "class BillingTask(BaseModel):\n",
        "    \"\"\"A billing inquiry task to be performed.\"\"\"\n",
        "    query_type: QueryTypeEnum = Field(description=\"The type of task to be performed.\", default=QueryTypeEnum.BILLING_INQUIRY)\n",
        "    invoice_number: str = Field(description=\"The invoice number to be used for the billing inquiry.\")\n",
        "    user_concern: str = Field(description=\"The concern or question the user has voiced about the invoice.\")\n",
        "    action_taken: str = Field(description=\"The action taken to address the user's concern.\")\n",
        "    resolution_eta: str = Field(description=\"The estimated time to resolve the concern.\")\n",
        "\n",
        "prompt_billing_worker_extractor = \"\"\"\n",
        "You are a specialized assistant. A user has a query regarding invoice '{invoice_number}'.\n",
        "From the full user query provided below, extract the specific concern or question the user has voiced about this particular invoice.\n",
        "Respond with ONLY the extracted concern/question. If no specific concern is mentioned beyond a general inquiry about the invoice, state 'General inquiry regarding the invoice'.\n",
        "\n",
        "Here's the user's query:\n",
        "<user_query>\n",
        "{original_user_query}\n",
        "</user_query>\n",
        "\n",
        "Extracted concern about invoice {invoice_number}:\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "def handle_billing_worker(invoice_number: str, original_user_query: str) -> BillingTask:\n",
        "    \"\"\"\n",
        "    Handles a billing inquiry.\n",
        "    1. Uses an LLM to extract the specific concern about the invoice from the original query.\n",
        "    2. Simulates opening an investigation.\n",
        "    3. Returns structured data about the action taken.\n",
        "    \"\"\"\n",
        "    extraction_prompt = prompt_billing_worker_extractor.format(\n",
        "        invoice_number=invoice_number, original_user_query=original_user_query\n",
        "    )\n",
        "    response = client.models.generate_content(model=MODEL_ID, contents=extraction_prompt)\n",
        "    extracted_concern = response.text\n",
        "\n",
        "    # Simulate backend action: opening an investigation\n",
        "    investigation_id = f\"INV_CASE_{random.randint(1000, 9999)}\"\n",
        "    eta_days = 2\n",
        "\n",
        "    task = BillingTask(\n",
        "        invoice_number=invoice_number,\n",
        "        user_concern=extracted_concern,\n",
        "        action_taken=f\"An investigation (Case ID: {investigation_id}) has been opened regarding your concern.\",\n",
        "        resolution_eta=f\"{eta_days} business days\",\n",
        "    )\n",
        "\n",
        "    return task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKqsMwiXj7H3"
      },
      "source": [
        "### Product Return Worker\n",
        "\n",
        "The return worker handles product return requests by generating RMA (Return Merchandise Authorization) numbers and providing detailed shipping instructions for customers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FNIgq12SYGr0"
      },
      "outputs": [],
      "source": [
        "class ReturnTask(BaseModel):\n",
        "    \"\"\"A task to handle a product return request.\"\"\"\n",
        "    query_type: QueryTypeEnum = Field(description=\"The type of task to be performed.\", default=QueryTypeEnum.PRODUCT_RETURN)\n",
        "    product_name: str = Field(description=\"The name of the product to be returned.\")\n",
        "    reason_for_return: str = Field(description=\"The reason for returning the product.\")\n",
        "    rma_number: str = Field(description=\"The RMA number for the return.\")\n",
        "    shipping_instructions: str = Field(description=\"The shipping instructions for the return.\")\n",
        "\n",
        "\n",
        "def handle_return_worker(product_name: str, reason_for_return: str) -> ReturnTask:\n",
        "    \"\"\"\n",
        "    Handles a product return request.\n",
        "    1. Simulates generating an RMA number and providing return instructions.\n",
        "    2. Returns structured data.\n",
        "    \"\"\"\n",
        "    # Simulate backend action: generating RMA and getting instructions\n",
        "    rma_number = f\"RMA-{random.randint(10000, 99999)}\"\n",
        "    shipping_instructions = (\n",
        "        \"Please pack the '{product_name}' securely in its original packaging if possible. \"\n",
        "        \"Include all accessories and manuals. Write the RMA number ({rma_number}) clearly on the outside of the package. \"\n",
        "        \"Ship to: Returns Department, 123 Automation Lane, Tech City, TC 98765.\"\n",
        "    ).format(product_name=product_name, rma_number=rma_number)\n",
        "\n",
        "    task = ReturnTask(\n",
        "        product_name=product_name,\n",
        "        reason_for_return=reason_for_return,\n",
        "        rma_number=rma_number,\n",
        "        shipping_instructions=shipping_instructions,\n",
        "    )\n",
        "\n",
        "    return task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEf-wrHtj7H3"
      },
      "source": [
        "### Order Status Worker\n",
        "\n",
        "The status worker retrieves and formats order status information, including shipping details, tracking numbers, and delivery estimates:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8KrXP3bJYMNA"
      },
      "outputs": [],
      "source": [
        "class StatusTask(BaseModel):\n",
        "    \"\"\"A task to handle an order status update request.\"\"\"\n",
        "    query_type: QueryTypeEnum = Field(description=\"The type of task to be performed.\", default=QueryTypeEnum.STATUS_UPDATE)\n",
        "    order_id: str = Field(description=\"The order ID to be used for the status update.\")\n",
        "    current_status: str = Field(description=\"The current status of the order.\")\n",
        "    carrier: str = Field(description=\"The carrier of the order.\")\n",
        "    tracking_number: str = Field(description=\"The tracking number of the order.\")\n",
        "    expected_delivery: str = Field(description=\"The expected delivery date of the order.\")\n",
        "\n",
        "def handle_status_worker(order_id: str) -> StatusTask:\n",
        "    \"\"\"\n",
        "    Handles an order status update request.\n",
        "    1. Simulates fetching order status from a backend system.\n",
        "    2. Returns structured data.\n",
        "    \"\"\"\n",
        "    # Simulate backend action: fetching order status\n",
        "    # Possible statuses and details to make it more dynamic\n",
        "    possible_statuses = [\n",
        "        {\"status\": \"Processing\", \"carrier\": \"N/A\", \"tracking\": \"N/A\", \"delivery_estimate\": \"3-5 business days\"},\n",
        "        {\n",
        "            \"status\": \"Shipped\",\n",
        "            \"carrier\": \"SuperFast Shipping\",\n",
        "            \"tracking\": f\"SF{random.randint(100000, 999999)}\",\n",
        "            \"delivery_estimate\": \"Tomorrow\",\n",
        "        },\n",
        "        {\n",
        "            \"status\": \"Delivered\",\n",
        "            \"carrier\": \"Local Courier\",\n",
        "            \"tracking\": f\"LC{random.randint(10000, 99999)}\",\n",
        "            \"delivery_estimate\": \"Delivered yesterday\",\n",
        "        },\n",
        "        {\n",
        "            \"status\": \"Delayed\",\n",
        "            \"carrier\": \"Standard Post\",\n",
        "            \"tracking\": f\"SP{random.randint(10000, 99999)}\",\n",
        "            \"delivery_estimate\": \"Expected in 2-3 additional days\",\n",
        "        },\n",
        "    ]\n",
        "    # For a given order_id, we could hash it to pick a status or just pick one randomly for this example\n",
        "    # This ensures that for the same order_id in a single run, we'd get the same fake status if we implement a simple hash.\n",
        "    # For now, let's pick randomly for demonstration.\n",
        "    status_details = random.choice(possible_statuses)\n",
        "\n",
        "    task = StatusTask(\n",
        "        order_id=order_id,\n",
        "        current_status=status_details[\"status\"],\n",
        "        carrier=status_details[\"carrier\"],\n",
        "        tracking_number=status_details[\"tracking\"],\n",
        "        expected_delivery=status_details[\"delivery_estimate\"],\n",
        "    )\n",
        "\n",
        "    return task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM_yBGWWj7IA"
      },
      "source": [
        "### Response Synthesizer\n",
        "\n",
        "The synthesizer takes the structured results from all workers and combines them into a single, coherent, and customer-friendly response message:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lJBok1WLYUMe"
      },
      "outputs": [],
      "source": [
        "prompt_synthesizer = \"\"\"\n",
        "You are a master communicator. Combine several distinct pieces of information from our support team into a single, well-formatted, and friendly email to a customer.\n",
        "\n",
        "Here are the points to include, based on the actions taken for their query:\n",
        "<points>\n",
        "{formatted_results}\n",
        "</points>\n",
        "\n",
        "Combine these points into one cohesive response.\n",
        "Start with a friendly greeting (e.g., \"Dear Customer,\" or \"Hi there,\") and end with a polite closing (e.g., \"Sincerely,\" or \"Best regards,\").\n",
        "Ensure the tone is helpful and professional.\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "def synthesizer(results: list[Task]) -> str:\n",
        "    \"\"\"Combines structured results from workers into a single user-facing message.\"\"\"\n",
        "    bullet_points = []\n",
        "    for res in results:\n",
        "        point = f\"Regarding your {res.query_type}:\\n\"\n",
        "        if res.query_type == QueryTypeEnum.BILLING_INQUIRY:\n",
        "            res: BillingTask = res\n",
        "            point += f\"  - Invoice Number: {res.invoice_number}\\n\"\n",
        "            point += f'  - Your Stated Concern: \"{res.user_concern}\"\\n'\n",
        "            point += f\"  - Our Action: {res.action_taken}\\n\"\n",
        "            point += f\"  - Expected Resolution: We will get back to you within {res.resolution_eta}.\"\n",
        "        elif res.query_type == QueryTypeEnum.PRODUCT_RETURN:\n",
        "            res: ReturnTask = res\n",
        "            point += f\"  - Product: {res.product_name}\\n\"\n",
        "            point += f'  - Reason for Return: \"{res.reason_for_return}\"\\n'\n",
        "            point += f\"  - Return Authorization (RMA): {res.rma_number}\\n\"\n",
        "            point += f\"  - Instructions: {res.shipping_instructions}\"\n",
        "        elif res.query_type == QueryTypeEnum.STATUS_UPDATE:\n",
        "            res: StatusTask = res\n",
        "            point += f\"  - Order ID: {res.order_id}\\n\"\n",
        "            point += f\"  - Current Status: {res.current_status}\\n\"\n",
        "            if res.carrier != \"N/A\":\n",
        "                point += f\"  - Carrier: {res.carrier}\\n\"\n",
        "            if res.tracking_number != \"N/A\":\n",
        "                point += f\"  - Tracking Number: {res.tracking_number}\\n\"\n",
        "            point += f\"  - Delivery Estimate: {res.expected_delivery}\"\n",
        "        bullet_points.append(point)\n",
        "\n",
        "    formatted_results = \"\\n\\n\".join(bullet_points)\n",
        "    prompt = prompt_synthesizer.format(formatted_results=formatted_results)\n",
        "    response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAUQR4ONj7IA"
      },
      "source": [
        "### Main Orchestrator-Worker Pipeline\n",
        "\n",
        "This function coordinates the entire orchestrator-worker workflow: it runs the orchestrator to break down the query, dispatches the appropriate workers, and synthesizes the final response:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2BO01w-xXR8q"
      },
      "outputs": [],
      "source": [
        "def process_user_query(user_query):\n",
        "    \"\"\"Processes a query using the Orchestrator-Worker-Synthesizer pattern.\"\"\"\n",
        "\n",
        "    pretty_print.wrapped(\n",
        "        text=user_query,\n",
        "        title=\"User query\"\n",
        "    )\n",
        "\n",
        "    # 1. Run orchestrator\n",
        "    tasks_list = orchestrator(user_query)\n",
        "    if not tasks_list:\n",
        "        print(\"Orchestrator did not return any tasks. Exiting.\")\n",
        "        return\n",
        "\n",
        "    for i, task in enumerate(tasks_list, start=1):\n",
        "        pretty_print.wrapped(\n",
        "            text=task.model_dump_json(indent=2),\n",
        "            title=f\"Deconstructed task {i}\",\n",
        "            header_color=pretty_print.Color.MAGENTA\n",
        "        )\n",
        "\n",
        "    # 2. Run workers\n",
        "    worker_results = []\n",
        "    if tasks_list:\n",
        "        for task in tasks_list:\n",
        "            if task.query_type == QueryTypeEnum.BILLING_INQUIRY:\n",
        "                worker_results.append(handle_billing_worker(task.invoice_number, user_query))\n",
        "            elif task.query_type == QueryTypeEnum.PRODUCT_RETURN:\n",
        "                worker_results.append(handle_return_worker(task.product_name, task.reason_for_return))\n",
        "            elif task.query_type == QueryTypeEnum.STATUS_UPDATE:\n",
        "                worker_results.append(handle_status_worker(task.order_id))\n",
        "            else:\n",
        "                print(f\"Warning: Unknown query_type '{task.query_type}' found in orchestrator tasks.\")\n",
        "\n",
        "        if worker_results:\n",
        "            for i, res in enumerate(worker_results, start=1):\n",
        "                pretty_print.wrapped(\n",
        "                    text=res.model_dump_json(indent=2),\n",
        "                    title=f\"Worker result {i}\",\n",
        "                    header_color=pretty_print.Color.CYAN\n",
        "                )\n",
        "        else:\n",
        "            print(\"No valid worker tasks to run.\")\n",
        "    else:\n",
        "        print(\"No tasks to run for workers.\")\n",
        "\n",
        "    # 3. Run synthesizer\n",
        "    if worker_results:\n",
        "        final_user_message = synthesizer(worker_results)\n",
        "        pretty_print.wrapped(\n",
        "            text=final_user_message,\n",
        "            title=\"Final synthesized response\",\n",
        "            header_color=pretty_print.Color.GREEN\n",
        "        )\n",
        "    else:\n",
        "        print(\"Skipping synthesis because there were no worker results.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVNNvD4ej7IA"
      },
      "source": [
        "### Testing the Complete Workflow\n",
        "\n",
        "Let's test our orchestrator-worker pattern with a complex customer query that involves multiple tasks: a billing inquiry, a product return, and an order status update:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTHwtUtqYxuK",
        "outputId": "8303ad98-d356-487d-d580-21d2f0293be0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[93m-------------------------------------------- User query --------------------------------------------\u001b[0m\n",
            "  Hi, I'm writing to you because I have a question about invoice #INV-7890. It seems higher than I expected.\n",
            "Also, I would like to return the 'SuperWidget 5000' I bought because it's not compatible with my system.\n",
            "Finally, can you give me an update on my order #A-12345?\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[95m--------------------------------------- Deconstructed task 1 ---------------------------------------\u001b[0m\n",
            "  {\n",
            "  \"query_type\": \"BillingInquiry\",\n",
            "  \"invoice_number\": \"INV-7890\",\n",
            "  \"product_name\": null,\n",
            "  \"reason_for_return\": null,\n",
            "  \"order_id\": null\n",
            "}\n",
            "\u001b[95m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[95m--------------------------------------- Deconstructed task 2 ---------------------------------------\u001b[0m\n",
            "  {\n",
            "  \"query_type\": \"ProductReturn\",\n",
            "  \"invoice_number\": null,\n",
            "  \"product_name\": \"SuperWidget 5000\",\n",
            "  \"reason_for_return\": \"not compatible with my system\",\n",
            "  \"order_id\": null\n",
            "}\n",
            "\u001b[95m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[95m--------------------------------------- Deconstructed task 3 ---------------------------------------\u001b[0m\n",
            "  {\n",
            "  \"query_type\": \"StatusUpdate\",\n",
            "  \"invoice_number\": null,\n",
            "  \"product_name\": null,\n",
            "  \"reason_for_return\": null,\n",
            "  \"order_id\": \"A-12345\"\n",
            "}\n",
            "\u001b[95m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[96m----------------------------------------- Worker result 1 -----------------------------------------\u001b[0m\n",
            "  {\n",
            "  \"query_type\": \"BillingInquiry\",\n",
            "  \"invoice_number\": \"INV-7890\",\n",
            "  \"user_concern\": \"It seems higher than I expected.\",\n",
            "  \"action_taken\": \"An investigation (Case ID: INV_CASE_1020) has been opened regarding your concern.\",\n",
            "  \"resolution_eta\": \"2 business days\"\n",
            "}\n",
            "\u001b[96m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[96m----------------------------------------- Worker result 2 -----------------------------------------\u001b[0m\n",
            "  {\n",
            "  \"query_type\": \"ProductReturn\",\n",
            "  \"product_name\": \"SuperWidget 5000\",\n",
            "  \"reason_for_return\": \"not compatible with my system\",\n",
            "  \"rma_number\": \"RMA-21819\",\n",
            "  \"shipping_instructions\": \"Please pack the 'SuperWidget 5000' securely in its original packaging if possible. Include all accessories and manuals. Write the RMA number (RMA-21819) clearly on the outside of the package. Ship to: Returns Department, 123 Automation Lane, Tech City, TC 98765.\"\n",
            "}\n",
            "\u001b[96m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[96m----------------------------------------- Worker result 3 -----------------------------------------\u001b[0m\n",
            "  {\n",
            "  \"query_type\": \"StatusUpdate\",\n",
            "  \"order_id\": \"A-12345\",\n",
            "  \"current_status\": \"Processing\",\n",
            "  \"carrier\": \"N/A\",\n",
            "  \"tracking_number\": \"N/A\",\n",
            "  \"expected_delivery\": \"3-5 business days\"\n",
            "}\n",
            "\u001b[96m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[92m------------------------------------ Final synthesized response ------------------------------------\u001b[0m\n",
            "  Hi there,\n",
            "\n",
            "Thank you for reaching out to us! We've received your recent inquiries and are happy to provide updates on each of them.\n",
            "\n",
            "Here's a summary of the actions we've taken and the information you requested:\n",
            "\n",
            "---\n",
            "\n",
            "**Regarding Your Billing Inquiry (Invoice Number: INV-7890)**\n",
            "We understand your concern that the amount \"seems higher than expected.\" Please be assured that we're taking this seriously.\n",
            "*   An investigation has been opened under **Case ID: INV_CASE_1020** to thoroughly review your invoice details.\n",
            "*   We expect to get back to you with a resolution or a comprehensive update within **2 business days**.\n",
            "\n",
            "---\n",
            "\n",
            "**Regarding Your Product Return (SuperWidget 5000)**\n",
            "We've processed your return authorization for the **SuperWidget 5000** you mentioned was \"not compatible with your system.\"\n",
            "*   Your Return Merchandise Authorization (RMA) number is: **RMA-21819**.\n",
            "*   To ensure a smooth return process, please follow these instructions:\n",
            "    *   Securely pack the **SuperWidget 5000** (along with all accessories and manuals), ideally in its original packaging.\n",
            "    *   Clearly write your RMA number (**RMA-21819**) on the outside of the package.\n",
            "    *   Ship the package to:\n",
            "        Returns Department\n",
            "        123 Automation Lane\n",
            "        Tech City, TC 98765\n",
            "\n",
            "---\n",
            "\n",
            "**Regarding Your Order Status Update (Order ID: A-12345)**\n",
            "We're happy to provide an update on your recent order.\n",
            "*   Your order (**A-12345**) is currently **Processing**.\n",
            "*   You can expect delivery within **3-5 business days**.\n",
            "\n",
            "---\n",
            "\n",
            "We hope this clarifies all your current inquiries. If you have any further questions or require additional assistance, please don't hesitate to reply to this email.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "The Support Team\n",
            "\u001b[92m----------------------------------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Test with customer query\n",
        "complex_customer_query = \"\"\"\n",
        "Hi, I'm writing to you because I have a question about invoice #INV-7890. It seems higher than I expected.\n",
        "Also, I would like to return the 'SuperWidget 5000' I bought because it's not compatible with my system.\n",
        "Finally, can you give me an update on my order #A-12345?\n",
        "\"\"\".strip()\n",
        "\n",
        "process_user_query(complex_customer_query)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
