{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 6: Tools\n",
    "\n",
    "This notebook explores **Tools (Function Calling)**, one of the key building blocks of an AI agent. \n",
    "\n",
    "We will use the `google-genai` library to interact with Google's Gemini models.\n",
    "\n",
    "Learning Objectives:\n",
    "\n",
    "1.  Understand and implement tool use (function calling) from scratch to allow an LLM to interact with external systems.\n",
    "2.  Build a custom tool calling framework using decorators similar to production frameworks like LangGraph.\n",
    "3.  Use Gemini's native tool calling API for production-ready implementations.\n",
    "4.  Implement structured data extraction using Pydantic models as tools for reliable structured outputs.\n",
    "5.  Run tools in a loop to handle multi-step tasks and understand the limitations that lead to the popular ReAct pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "### Set Up Python Environment\n",
    "\n",
    "Run the following command to install all the required packages to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q \\\n",
    "  agentic-ai-engineering-course \\\n",
    "  google-auth==2.38.0 \\\n",
    "  opentelemetry-api==1.37.0 opentelemetry-sdk==1.37.0 \\\n",
    "  opentelemetry-exporter-otlp-proto-http==1.37.0 \\\n",
    "  opentelemetry-exporter-otlp-proto-common==1.37.0 \\\n",
    "  opentelemetry-proto==1.37.0 \\\n",
    "  jedi==0.18.2\n",
    "\n",
    "%pip check\n",
    "import IPython; IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Gemini API\n",
    "\n",
    "To configure the Gemini API, follow the step-by-step instructions from the `Course Admin` lesson.\n",
    "\n",
    "But here is a quick check on what you need to run this Notebook:\n",
    "\n",
    "1.  Get your key from [Google AI Studio](https://aistudio.google.com/app/apikey).\n",
    "\n",
    "2. In Google Colab, go to the \"Secrets\" tab (or the key icon) on the left-hand panel.\n",
    "\n",
    "3. Click \"Add new secret\" and create a new secret with the following details:\n",
    "\n",
    "    - Name: GOOGLE_API_KEY \n",
    "\n",
    "    - Value: Paste your API key here.\n",
    "\n",
    "4. Make sure to enable the option \"Notebook access\".\n",
    "\n",
    "Now, the code below will load the key from your Colab secrets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load environment variables from `/Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.env`\n",
      "Environment variables loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from utils import env\n",
    "\n",
    "env.load(required_env_vars=[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Key Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Any\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from utils import pretty_print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Gemini Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Constants\n",
    "\n",
    "We will use the `gemini-2.5-flash` model, which is fast and cost-effective. We also define a sample financial document that will be used throughout our examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.5-flash\"\n",
    "\n",
    "DOCUMENT = \"\"\"\n",
    "# Q3 2023 Financial Performance Analysis\n",
    "\n",
    "The Q3 earnings report shows a 20% increase in revenue and a 15% growth in user engagement, \n",
    "beating market expectations. These impressive results reflect our successful product strategy \n",
    "and strong market positioning.\n",
    "\n",
    "Our core business segments demonstrated remarkable resilience, with digital services leading \n",
    "the growth at 25% year-over-year. The expansion into new markets has proven particularly \n",
    "successful, contributing to 30% of the total revenue increase.\n",
    "\n",
    "Customer acquisition costs decreased by 10% while retention rates improved to 92%, \n",
    "marking our best performance to date. These metrics, combined with our healthy cash flow \n",
    "position, provide a strong foundation for continued growth into Q4 and beyond.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementing tool calls from scratch\n",
    "\n",
    "LLMs are trained on text and can't perform actions in the real world on their own. Tools (or function calling) are the mechanism we use to bridge this gap. We provide the LLM with a list of available tools, and it can decide which one to use and with what arguments to fulfill a user's request.\n",
    "\n",
    "The process of calling a tool looks as follows:\n",
    "\n",
    "1. **You:** Send the LLM a prompt and a list of available tools.\n",
    "2. **LLM:** Responds with a function call request, specifying the tool and arguments.\n",
    "3. **You:** Execute the requested function in your code.\n",
    "4. **You:** Send the function's output back to the LLM.\n",
    "5. **LLM:** Uses the tool's output to generate a final, user-facing response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Mock Tools\n",
    "\n",
    "Let's create three simple, mocked functions. One simulates searching Google Drive, another simulates sending a Discord message, and the last one simulates summarizing a document. \n",
    "\n",
    "The function signature (input parameters and output type) and docstrings are crucial, as the LLM uses them to understand what each tool does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_google_drive(query: str) -> dict:\n",
    "    \"\"\"\n",
    "    Searches for a file on Google Drive and returns its content or a summary.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query to find the file, e.g., 'Q3 earnings report'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary representing the search results, including file names and summaries.\n",
    "    \"\"\"\n",
    "\n",
    "    # Here, we mock the response for demonstration.\n",
    "    # In a real scenario, this would interact with the Google Drive API.\n",
    "    return {\n",
    "        \"files\": [\n",
    "            {\n",
    "                \"name\": \"Q3_Earnings_Report_2024.pdf\",\n",
    "                \"id\": \"file12345\",\n",
    "                \"content\": DOCUMENT,\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def send_discord_message(channel_id: str, message: str) -> dict:\n",
    "    \"\"\"\n",
    "    Sends a message to a specific Discord channel.\n",
    "\n",
    "    Args:\n",
    "        channel_id (str): The ID of the channel to send the message to, e.g., '#finance'.\n",
    "        message (str): The content of the message to send.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary confirming the action, e.g., {\"status\": \"success\"}.\n",
    "    \"\"\"\n",
    "\n",
    "    # Mocking a successful API call to Discord.\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"status_code\": 200,\n",
    "        \"channel\": channel_id,\n",
    "        \"message_preview\": f\"{message[:50]}...\",\n",
    "    }\n",
    "\n",
    "\n",
    "def summarize_financial_report(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Summarizes a financial report.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to summarize.\n",
    "\n",
    "    Returns:\n",
    "        str: The summary of the text.\n",
    "    \"\"\"\n",
    "\n",
    "    # Mocked summary for demonstration.\n",
    "    return \"The Q3 2023 earnings report shows strong performance across all metrics \\\n",
    "with 20% revenue growth, 15% user engagement increase, 25% digital services growth, and \\\n",
    "improved retention rates of 92%.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to define the metadata for each function, which will be used as input to the LLM to understand which tool to use and how to call it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_google_drive_schema = {\n",
    "    \"name\": \"search_google_drive\",\n",
    "    \"description\": \"Searches for a file on Google Drive and returns its content or a summary.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The search query to find the file, e.g., 'Q3 earnings report'.\",\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "send_discord_message_schema = {\n",
    "    \"name\": \"send_discord_message\",\n",
    "    \"description\": \"Sends a message to a specific Discord channel.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"channel_id\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The ID of the channel to send the message to, e.g., '#finance'.\",\n",
    "            },\n",
    "            \"message\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The content of the message to send.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"channel_id\", \"message\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "summarize_financial_report_schema = {\n",
    "    \"name\": \"summarize_financial_report\",\n",
    "    \"description\": \"Summarizes a financial report.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"text\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The text to summarize.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"text\"],\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, we will aggregate all the tools in a single dictionary, known as the tools registry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOLS = {\n",
    "    \"search_google_drive\": {\n",
    "        \"handler\": search_google_drive,\n",
    "        \"schema\": search_google_drive_schema,\n",
    "    },\n",
    "    \"send_discord_message\": {\n",
    "        \"handler\": send_discord_message,\n",
    "        \"schema\": send_discord_message_schema,\n",
    "    },\n",
    "    \"summarize_financial_report\": {\n",
    "        \"handler\": summarize_financial_report,\n",
    "        \"schema\": summarize_financial_report_schema,\n",
    "    },\n",
    "}\n",
    "TOOLS_BY_NAME = {tool_name: tool[\"handler\"] for tool_name, tool in TOOLS.items()}\n",
    "TOOLS_SCHEMA = [tool[\"schema\"] for tool in TOOLS.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool name: search_google_drive\n",
      "Tool handler: <function search_google_drive at 0x10ad91e40>\n",
      "---------------------------------------------------------------------------\n",
      "Tool name: send_discord_message\n",
      "Tool handler: <function send_discord_message at 0x10fef5b20>\n",
      "---------------------------------------------------------------------------\n",
      "Tool name: summarize_financial_report\n",
      "Tool handler: <function summarize_financial_report at 0x10fef5bc0>\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for tool_name, tool in TOOLS_BY_NAME.items():\n",
    "    print(f\"Tool name: {tool_name}\")\n",
    "    print(f\"Tool handler: {tool}\")\n",
    "    print(\"-\" * 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m-------------------------------- `search_google_drive` Tool Schema --------------------------------\u001b[0m\n",
      "  {\n",
      "  \"name\": \"search_google_drive\",\n",
      "  \"description\": \"Searches for a file on Google Drive and returns its content or a summary.\",\n",
      "  \"parameters\": {\n",
      "    \"type\": \"object\",\n",
      "    \"properties\": {\n",
      "      \"query\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"The search query to find the file, e.g., 'Q3 earnings report'.\"\n",
      "      }\n",
      "    },\n",
      "    \"required\": [\n",
      "      \"query\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print.wrapped(json.dumps(TOOLS_SCHEMA[0], indent=2), title=\"`search_google_drive` Tool Schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m-------------------------------- `send_discord_message` Tool Schema --------------------------------\u001b[0m\n",
      "  {\n",
      "  \"name\": \"send_discord_message\",\n",
      "  \"description\": \"Sends a message to a specific Discord channel.\",\n",
      "  \"parameters\": {\n",
      "    \"type\": \"object\",\n",
      "    \"properties\": {\n",
      "      \"channel_id\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"The ID of the channel to send the message to, e.g., '#finance'.\"\n",
      "      },\n",
      "      \"message\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"The content of the message to send.\"\n",
      "      }\n",
      "    },\n",
      "    \"required\": [\n",
      "      \"channel_id\",\n",
      "      \"message\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print.wrapped(json.dumps(TOOLS_SCHEMA[1], indent=2), title=\"`send_discord_message` Tool Schema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how to call these tools using an LLM. First, we need to define the system prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOL_CALLING_SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful AI assistant with access to tools that enable you to take actions and retrieve information to better \n",
    "assist users.\n",
    "\n",
    "## Tool Usage Guidelines\n",
    "\n",
    "**When to use tools:**\n",
    "- When you need information that is not in your training data\n",
    "- When you need to perform actions in external systems and environments\n",
    "- When you need real-time, dynamic, or user-specific data\n",
    "- When computational operations are required\n",
    "\n",
    "**Tool selection:**\n",
    "- Choose the most appropriate tool based on the user's specific request\n",
    "- If multiple tools could work, select the one that most directly addresses the need\n",
    "- Consider the order of operations for multi-step tasks\n",
    "\n",
    "**Parameter requirements:**\n",
    "- Provide all required parameters with accurate values\n",
    "- Use the parameter descriptions to understand expected formats and constraints\n",
    "- Ensure data types match the tool's requirements (strings, numbers, booleans, arrays)\n",
    "\n",
    "## Tool Call Format\n",
    "\n",
    "When you need to use a tool, output ONLY the tool call in this exact format:\n",
    "\n",
    "```tool_call\n",
    "{{\"name\": \"tool_name\", \"args\": {{\"param1\": \"value1\", \"param2\": \"value2\"}}}}\n",
    "```\n",
    "\n",
    "**Critical formatting rules:**\n",
    "- Use double quotes for all JSON strings\n",
    "- Ensure the JSON is valid and properly escaped\n",
    "- Include ALL required parameters\n",
    "- Use correct data types as specified in the tool definition\n",
    "- Do not include any additional text or explanation in the tool call\n",
    "\n",
    "## Response Behavior\n",
    "\n",
    "- If no tools are needed, respond directly to the user with helpful information\n",
    "- If tools are needed, make the tool call first, then provide context about what you're doing\n",
    "- After receiving tool results, provide a clear, user-friendly explanation of the outcome\n",
    "- If a tool call fails, explain the issue and suggest alternatives when possible\n",
    "\n",
    "## Available Tools\n",
    "\n",
    "<tool_definitions>\n",
    "{tools}\n",
    "</tool_definitions>\n",
    "\n",
    "Your goal is to be maximally helpful to the user. Use tools when they add value, but don't use them unnecessarily.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the prompt with a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m-------------------------------------- LLM Tool Call Response --------------------------------------\u001b[0m\n",
      "  ```tool_call\n",
      "{\"name\": \"search_google_drive\", \"args\": {\"query\": \"latest quarterly report\"}}\n",
      "```\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "USER_PROMPT = \"\"\"\n",
    "Can you help me find the latest quarterly report and share key insights with the team?\n",
    "\"\"\"\n",
    "\n",
    "messages = [TOOL_CALLING_SYSTEM_PROMPT.format(tools=str(TOOLS_SCHEMA)), USER_PROMPT]\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=messages,\n",
    ")\n",
    "\n",
    "pretty_print.wrapped(response.text, title=\"LLM Tool Call Response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m-------------------------------------- LLM Tool Call Response --------------------------------------\u001b[0m\n",
      "  ```tool_call\n",
      "{\"name\": \"send_discord_message\", \"args\": {\"channel_id\": \"#finance\", \"message\": \"Hello everyone!\"}}\n",
      "```\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "USER_PROMPT = \"\"\"\n",
    "Send a greeting message to the #finance channel on Discord.\n",
    "\"\"\"\n",
    "\n",
    "messages = [TOOL_CALLING_SYSTEM_PROMPT.format(tools=str(TOOLS_SCHEMA)), USER_PROMPT]\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=messages,\n",
    ")\n",
    "pretty_print.wrapped(response.text, title=\"LLM Tool Call Response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to parse the LLM response and call the tool using Python.\n",
    "\n",
    "First, we parse the LLM output to extract the JSON from the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"send_discord_message\", \"args\": {\"channel_id\": \"#finance\", \"message\": \"Hello everyone!\"}}'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_tool_call(response_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the tool call from the response text.\n",
    "    \"\"\"\n",
    "    return response_text.split(\"```tool_call\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "\n",
    "tool_call_str = extract_tool_call(response.text)\n",
    "tool_call_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we parse the stringified JSON to a Python dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'send_discord_message',\n",
       " 'args': {'channel_id': '#finance', 'message': 'Hello everyone!'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = json.loads(tool_call_str)\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we retrieve the tool handler, which is a Python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.send_discord_message(channel_id: str, message: str) -> dict>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_handler = TOOLS_BY_NAME[tool_call[\"name\"]]\n",
    "tool_handler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, we call the Python function using the arguments generated by the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m-------------------------------------- LLM Tool Call Response --------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"status\": \"success\",\n",
      "  \"status_code\": 200,\n",
      "  \"channel\": \"#finance\",\n",
      "  \"message_preview\": \"Hello everyone!...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tool_result = tool_handler(**tool_call[\"args\"])\n",
    "pretty_print.wrapped(tool_result, indent=2, title=\"LLM Tool Call Response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can summarize the tool execution in the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_tool(response_text: str, tools_by_name: dict) -> Any:\n",
    "    \"\"\"\n",
    "    Call a tool based on the response from the LLM.\n",
    "\n",
    "    Args:\n",
    "        response_text (str): The raw response text from the LLM containing the tool call.\n",
    "        tools_by_name (dict): Dictionary mapping tool names to their handler functions.\n",
    "\n",
    "    Returns:\n",
    "        Any: The result of executing the tool with the provided arguments.\n",
    "    \"\"\"\n",
    "\n",
    "    tool_call_str = extract_tool_call(response_text)\n",
    "    tool_call = json.loads(tool_call_str)\n",
    "    tool_name = tool_call[\"name\"]\n",
    "    tool_args = tool_call[\"args\"]\n",
    "    tool = tools_by_name[tool_name]\n",
    "\n",
    "    return tool(**tool_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m-------------------------------------- LLM Tool Call Response --------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"status\": \"success\",\n",
      "  \"status_code\": 200,\n",
      "  \"channel\": \"#finance\",\n",
      "  \"message_preview\": \"Hello everyone!...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print.wrapped(\n",
    "    json.dumps(call_tool(response.text, tools_by_name=TOOLS_BY_NAME), indent=2), title=\"LLM Tool Call Response\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, before showing it to the user, we want the LLM to interpret the tool output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m-------------------------------------- LLM Tool Call Response --------------------------------------\u001b[0m\n",
      "  This tool result indicates the following:\n",
      "\n",
      "*   **Overall Success:** The operation performed by the tool completed successfully, as indicated by `\"status\": \"success\"` and the standard HTTP success code `\"status_code\": 200`.\n",
      "*   **Target Channel:** The action was specifically directed towards, or involved, the Slack/chat channel named **`#finance`**.\n",
      "*   **Message Content:** A message was likely sent or processed, and its beginning content is previewed as **`\"Hello everyone!...\"`**.\n",
      "\n",
      "In summary, **a message starting with \"Hello everyone!...\" was successfully sent to or processed within the #finance channel.**\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=f\"Interpret the tool result: {json.dumps(tool_result, indent=2)}\",\n",
    ")\n",
    "pretty_print.wrapped(response.text, title=\"LLM Tool Call Response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the basic concept of tool calling! We've successfully implemented function calling from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementing a tool calling framework from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better analogy with what we see in frameworks such as LangGraph or MCP, let's define a `@tool` decorator that automatically computes the schemas defined above based on the function signature and docstring.\n",
    "\n",
    "First, we will define the `ToolFunction` class that aggregates the function's schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import Parameter, signature\n",
    "from typing import Any, Callable, Dict\n",
    "\n",
    "\n",
    "class ToolFunction:\n",
    "    def __init__(self, func: Callable, schema: Dict[str, Any]) -> None:\n",
    "        self.func = func\n",
    "        self.schema = schema\n",
    "        self.__name__ = func.__name__\n",
    "        self.__doc__ = func.__doc__\n",
    "\n",
    "    def __call__(self, *args: Any, **kwargs: Any) -> Any:\n",
    "        return self.func(*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define a `tools` registry that will aggregate all our decorated tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools: list[ToolFunction] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, let's define the actual `@tool` decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool() -> Callable[[Callable], ToolFunction]:\n",
    "    \"\"\"\n",
    "    A decorator that creates a tool schema from a function.\n",
    "\n",
    "    Returns:\n",
    "        A decorator function that wraps the original function and adds a schema\n",
    "    \"\"\"\n",
    "\n",
    "    def decorator(func: Callable) -> ToolFunction:\n",
    "        # Get function signature\n",
    "        sig = signature(func)\n",
    "\n",
    "        # Create parameters schema\n",
    "        properties = {}\n",
    "        required = []\n",
    "\n",
    "        for param_name, param in sig.parameters.items():\n",
    "            # Skip self for methods\n",
    "            if param_name == \"self\":\n",
    "                continue\n",
    "\n",
    "            param_schema = {\n",
    "                \"type\": \"string\",  # Default to string, can be enhanced with type hints\n",
    "                \"description\": f\"The {param_name} parameter\",  # Default description\n",
    "            }\n",
    "\n",
    "            # Add to required if parameter has no default value\n",
    "            if param.default == Parameter.empty:\n",
    "                required.append(param_name)\n",
    "\n",
    "            properties[param_name] = param_schema\n",
    "\n",
    "        # Create the tool schema\n",
    "        schema = {\n",
    "            \"name\": func.__name__,\n",
    "            \"description\": func.__doc__,\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": properties,\n",
    "                \"required\": required,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # Create the tool function and add it to the tools registry\n",
    "        tool = ToolFunction(func, schema)\n",
    "        tools.append(tool)\n",
    "\n",
    "        return tool\n",
    "\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's redefine our tools leveraging the `@tool` decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool()\n",
    "def search_google_drive_example(query: str) -> dict:\n",
    "    \"\"\"Search for files in Google Drive.\"\"\"\n",
    "    return {\"files\": [\"Q3 earnings report\"]}\n",
    "\n",
    "\n",
    "@tool()\n",
    "def send_discord_message_example(channel_id: str, message: str) -> dict:\n",
    "    \"\"\"Send a message to a Discord channel.\"\"\"\n",
    "    return {\"message\": \"Message sent successfully\"}\n",
    "\n",
    "\n",
    "@tool()\n",
    "def summarize_financial_report_example(text: str) -> str:\n",
    "    \"\"\"Summarize the contents of a financial report.\"\"\"\n",
    "    return \"Financial report summarized successfully\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the `tools` registry to look at all the available tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.ToolFunction at 0x10ffd9010>,\n",
       " <__main__.ToolFunction at 0x10ffdd6d0>,\n",
       " <__main__.ToolFunction at 0x10ffdc050>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first tool from the registry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search_google_drive_example'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[0].schema[\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the first tool from the registry is `search_google_drive_example`. As expected, after the function has been decorated, it has been wrapped into a `ToolFunction` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.ToolFunction"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tools[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has automatically computed the tool schema that will be passed to the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m----------------------------------- Search Google Drive Example -----------------------------------\u001b[0m\n",
      "  {\n",
      "  \"name\": \"search_google_drive_example\",\n",
      "  \"description\": \"Search for files in Google Drive.\",\n",
      "  \"parameters\": {\n",
      "    \"type\": \"object\",\n",
      "    \"properties\": {\n",
      "      \"query\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"The query parameter\"\n",
      "      }\n",
      "    },\n",
      "    \"required\": [\n",
      "      \"query\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print.wrapped(json.dumps(tools[0].schema, indent=2), title=\"Search Google Drive Example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and contains the actual function handler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.search_google_drive_example(query: str) -> dict>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_google_drive_example.func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this new method works with LLMs. First, we have to create our tool mappings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_by_name = {tool.schema[\"name\"]: tool.func for tool in tools}\n",
    "tools_schema = [tool.schema for tool in tools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------------- Tools Schema -------------------------------------------\u001b[0m\n",
      "  [\n",
      "  {\n",
      "    \"name\": \"search_google_drive_example\",\n",
      "    \"description\": \"Search for files in Google Drive.\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"query\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"The query parameter\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"query\"\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"send_discord_message_example\",\n",
      "    \"description\": \"Send a message to a Discord channel.\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"channel_id\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"The channel_id parameter\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"The message parameter\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"channel_id\",\n",
      "        \"message\"\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"summarize_financial_report_example\",\n",
      "    \"description\": \"Summarize the contents of a financial report.\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"text\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"The text parameter\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"text\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "]\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print.wrapped(json.dumps(tools_schema, indent=2), title=\"Tools Schema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's call the LLM by passing the tool schemas, as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m-------------------------------------- LLM Tool Call Response --------------------------------------\u001b[0m\n",
      "  ```tool_call\n",
      "{\"name\": \"search_google_drive_example\", \"args\": {\"query\": \"latest quarterly report\"}}\n",
      "```\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "USER_PROMPT = \"\"\"\n",
    "Can you help me find the latest quarterly report and share key insights with the team?\n",
    "\"\"\"\n",
    "\n",
    "messages = [TOOL_CALLING_SYSTEM_PROMPT.format(tools=str(tools_schema)), USER_PROMPT]\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=messages,\n",
    ")\n",
    "pretty_print.wrapped(response.text, title=\"LLM Tool Call Response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m-------------------------------------- LLM Tool Call Response --------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"files\": [\n",
      "    \"Q3 earnings report\"\n",
      "  ]\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print.wrapped(\n",
    "    json.dumps(call_tool(response.text, tools_by_name=tools_by_name), indent=2), title=\"LLM Tool Call Response\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voil√†! We have our little tool calling framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementing production-level tool calls with Gemini\n",
    "\n",
    "In production, most of the time, we don't implement tool calling from scratch. Instead, we leverage the native interface of a specific API such as Gemini or OpenAI. So, let's see how we can use Gemini's built-in tool calling capabilities instead of our custom implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    types.Tool(\n",
    "        function_declarations=[\n",
    "            types.FunctionDeclaration(**search_google_drive_schema),\n",
    "            types.FunctionDeclaration(**send_discord_message_schema),\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "config = types.GenerateContentConfig(\n",
    "    tools=tools,\n",
    "    # Constrained to always predict a function call\n",
    "    tool_config=types.ToolConfig(function_calling_config=types.FunctionCallingConfig(mode=\"ANY\")),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, when calling the LLM, we don't have to explicitly define a system prompt that guides the LLM on how to use the tools. Instead, we pass the tool schema to the LLM provider through the config, which will handle tool calling internally. This is more efficient, as they take care of optimizing tool/function calling for each specific model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------------- User Prompt -------------------------------------------\u001b[0m\n",
      "  \n",
      "Can you help me find the latest quarterly report and share key insights with the team?\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m----------------------------------- LLM Response - Function Call -----------------------------------\u001b[0m\n",
      "  id=None args={'query': 'latest quarterly report'} name='search_google_drive'\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print.wrapped(USER_PROMPT, title=\"User Prompt\")\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=USER_PROMPT,\n",
    "    config=config,\n",
    ")\n",
    "pretty_print.wrapped(str(response.candidates[0].content.parts[0].function_call), title=\"LLM Response - Function Call\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the implementation even more, Google's genai supports taking Python functions directly as input. Now, the SDK creates the schema based on the signature, type hints and pydocs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()\n",
    "config = types.GenerateContentConfig(\n",
    "    tools=[search_google_drive, send_discord_message],\n",
    "    tool_config=types.ToolConfig(function_calling_config=types.FunctionCallingConfig(mode=\"ANY\")),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's call the LLM again using the new config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------------- User Prompt -------------------------------------------\u001b[0m\n",
      "  \n",
      "Can you help me find the latest quarterly report and share key insights with the team?\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m----------------------------------- LLM Response - Function Call -----------------------------------\u001b[0m\n",
      "  id=None args={'channel_id': '#finance', 'message': 'Key insights from the latest quarterly report:\\n- 20% increase in revenue\\n- 15% growth in user engagement\\n- Beating market expectations\\n- Successful product strategy and strong market positioning\\n- Digital services leading growth at 25% year-over-year\\n- Expansion into new markets contributing to 30% of the total revenue increase.\\n- Customer acquisition costs decreased by 10%.\\n- Retention rates improved to 92%.\\n- Healthy cash flow position, providing a strong foundation for continued growth into Q4 and beyond.'} name='send_discord_message'\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print.wrapped(USER_PROMPT, title=\"User Prompt\")\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=USER_PROMPT,\n",
    "    config=config,\n",
    ")\n",
    "pretty_print.wrapped(str(response.candidates[0].content.parts[0].function_call), title=\"LLM Response - Function Call\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the LLM response better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionCall(id=None, args={'channel_id': '#finance', 'message': 'Key insights from the latest quarterly report:\\n- 20% increase in revenue\\n- 15% growth in user engagement\\n- Beating market expectations\\n- Successful product strategy and strong market positioning\\n- Digital services leading growth at 25% year-over-year\\n- Expansion into new markets contributing to 30% of the total revenue increase.\\n- Customer acquisition costs decreased by 10%.\\n- Retention rates improved to 92%.\\n- Healthy cash flow position, providing a strong foundation for continued growth into Q4 and beyond.'}, name='send_discord_message')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_message_part = response.candidates[0].content.parts[0]\n",
    "function_call = response_message_part.function_call\n",
    "function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m---------------------------------------- Function Call Args ----------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"channel_id\": \"#finance\",\n",
      "  \"message\": \"Key insights from the latest quarterly report:\\n- 20% increase in revenue\\n- 15% growth in user engagement\\n- Beating market expectations\\n- Successful product strategy and strong market positioning\\n- Digital services leading growth at 25% year-over-year\\n- Expansion into new markets contributing to 30% of the total revenue increase.\\n- Customer acquisition costs decreased by 10%.\\n- Retention rates improved to 92%.\\n- Healthy cash flow position, providing a strong foundation for continued growth into Q4 and beyond.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print.wrapped(function_call.args, title=\"Function Call Args\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.send_discord_message(channel_id: str, message: str) -> dict>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_handler = TOOLS_BY_NAME[function_call.name]\n",
    "tool_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'status_code': 200,\n",
       " 'channel': '#finance',\n",
       " 'message_preview': 'Key insights from the latest quarterly report:\\n- 2...'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_handler(**function_call.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a simplified function that works with Gemini's native function call objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_tool(function_call) -> Any:\n",
    "    tool_name = function_call.name\n",
    "    tool_args = function_call.args\n",
    "\n",
    "    tool_handler = TOOLS_BY_NAME[tool_name]\n",
    "\n",
    "    return tool_handler(**tool_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------------- Tool Result -------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"status\": \"success\",\n",
      "  \"status_code\": 200,\n",
      "  \"channel\": \"#finance\",\n",
      "  \"message_preview\": \"Key insights from the latest quarterly report:\\n- 2...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tool_result = call_tool(response_message_part.function_call)\n",
    "pretty_print.wrapped(tool_result, indent=2, title=\"Tool Result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using Pydantic models as tools for on-demand structured outputs\n",
    "\n",
    "When it comes to structured outputs, a more elegant and powerful pattern is to treat our Pydantic model *as a tool*. We can ask the model to \"call\" this Pydantic tool, and the arguments it generates will be our structured data.\n",
    "\n",
    "This combines the power of function calling with the robustness of Pydantic for structured data extraction. It's the recommended approach for complex data extraction tasks.\n",
    "\n",
    "Let's define the same Pydantic model as in the structured outputs lesson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentMetadata(BaseModel):\n",
    "    \"\"\"Pydantic class to hold structured metadata for a document.\"\"\"\n",
    "\n",
    "    summary: str = Field(description=\"A concise, 1-2 sentence summary of the document.\")\n",
    "    tags: list[str] = Field(description=\"A list of 3-5 high-level tags relevant to the document.\")\n",
    "    keywords: list[str] = Field(description=\"A list of specific keywords or concepts mentioned.\")\n",
    "    quarter: str = Field(description=\"The quarter of the financial year described in the document (e.g., Q3 2023).\")\n",
    "    growth_rate: str = Field(description=\"The growth rate of the company described in the document (e.g., 10%).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how to use it as a tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Pydantic class 'DocumentMetadata' is now our 'tool'\n",
    "extraction_tool = types.Tool(\n",
    "    function_declarations=[\n",
    "        types.FunctionDeclaration(\n",
    "            name=\"extract_metadata\",\n",
    "            description=\"Extracts structured metadata from a financial document.\",\n",
    "            parameters=DocumentMetadata.model_json_schema(),\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, we define the config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = types.GenerateContentConfig(\n",
    "    tools=[extraction_tool],\n",
    "    tool_config=types.ToolConfig(function_calling_config=types.FunctionCallingConfig(mode=\"ANY\")),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we call the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Please analyze the following document and extract its metadata.\n",
    "\n",
    "Document:\n",
    "<document>\n",
    "{DOCUMENT}\n",
    "</document>\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(model=MODEL_ID, contents=prompt, config=config)\n",
    "response_message_part = response.candidates[0].content.parts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------------ Function Call ------------------------------------------\u001b[0m\n",
      "  \u001b[38;5;208mFunction Name:\u001b[0m `extract_metadata\n",
      "  \u001b[38;5;208mFunction Arguments:\u001b[0m `{\n",
      "  \"summary\": \"The Q3 2023 earnings report shows a significant 20% increase in revenue and 15% growth in user engagement, exceeding market expectations due to successful product strategy and market expansion. Improved customer acquisition costs and retention rates further strengthen the company's financial position for continued growth.\",\n",
      "  \"keywords\": [\n",
      "    \"Q3 earnings report\",\n",
      "    \"revenue\",\n",
      "    \"user engagement\",\n",
      "    \"product strategy\",\n",
      "    \"market positioning\",\n",
      "    \"digital services\",\n",
      "    \"new markets\",\n",
      "    \"customer acquisition costs\",\n",
      "    \"retention rates\",\n",
      "    \"cash flow\"\n",
      "  ],\n",
      "  \"quarter\": \"Q3 2023\",\n",
      "  \"growth_rate\": \"20%\",\n",
      "  \"tags\": [\n",
      "    \"Financial Performance\",\n",
      "    \"Earnings Report\",\n",
      "    \"Revenue Growth\",\n",
      "    \"User Engagement\",\n",
      "    \"Market Expansion\"\n",
      "  ]\n",
      "}`\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "function_call = response_message_part.function_call\n",
    "pretty_print.function_call(function_call, title=\"Function Call\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's validate the output using Pydantic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  Validation successful!\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    document_metadata = DocumentMetadata(**function_call.args)\n",
    "    pretty_print.wrapped(\"Validation successful!\")\n",
    "except Exception as e:\n",
    "    pretty_print.wrapped(str(e), title=\"Validation Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. The downsides of running tools in a loop\n",
    "\n",
    "Now, let's implement a more sophisticated approach where we put tool calling in a loop with a conversation history. This allows the agent to perform multi-step tasks by calling multiple tools in sequence. Let's create a scenario where we ask the agent to find a report on Google Drive and then communicate its findings on Discord.\n",
    "\n",
    "First, we define the config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    types.Tool(\n",
    "        function_declarations=[\n",
    "            types.FunctionDeclaration(**search_google_drive_schema),\n",
    "            types.FunctionDeclaration(**send_discord_message_schema),\n",
    "            types.FunctionDeclaration(**summarize_financial_report_schema),\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "config = types.GenerateContentConfig(\n",
    "    tools=tools,\n",
    "    tool_config=types.ToolConfig(function_calling_config=types.FunctionCallingConfig(mode=\"ANY\")),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the user prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT = \"\"\"\n",
    "Please find the Q3 earnings report on Google Drive and send a summary of it to \n",
    "the #finance channel on Discord.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we make the first LLM call as always:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------------- User Prompt -------------------------------------------\u001b[0m\n",
      "  \n",
      "Please find the Q3 earnings report on Google Drive and send a summary of it to \n",
      "the #finance channel on Discord.\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m------------------------------------------ Function Call ------------------------------------------\u001b[0m\n",
      "  \u001b[38;5;208mFunction Name:\u001b[0m `search_google_drive\n",
      "  \u001b[38;5;208mFunction Arguments:\u001b[0m `{\n",
      "  \"query\": \"Q3 earnings report\"\n",
      "}`\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "messages = [USER_PROMPT]\n",
    "\n",
    "pretty_print.wrapped(USER_PROMPT, title=\"User Prompt\")\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=messages,\n",
    "    config=config,\n",
    ")\n",
    "response_message_part = response.candidates[0].content.parts[0]\n",
    "pretty_print.function_call(response_message_part.function_call, title=\"Function Call\")\n",
    "\n",
    "messages.append(response.candidates[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, we add the LLM in a loop until it doesn't return new `function_call` objects or it hits the `max_iterations` limit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------------- Tool Result -------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"files\": [\n",
      "    {\n",
      "      \"name\": \"Q3_Earnings_Report_2024.pdf\",\n",
      "      \"id\": \"file12345\",\n",
      "      \"content\": \"\\n# Q3 2023 Financial Performance Analysis\\n\\nThe Q3 earnings report shows a 20% increase in revenue and a 15% growth in user engagement, \\nbeating market expectations. These impressive results reflect our successful product strategy \\nand strong market positioning.\\n\\nOur core business segments demonstrated remarkable resilience, with digital services leading \\nthe growth at 25% year-over-year. The expansion into new markets has proven particularly \\nsuccessful, contributing to 30% of the total revenue increase.\\n\\nCustomer acquisition costs decreased by 10% while retention rates improved to 92%, \\nmarking our best performance to date. These metrics, combined with our healthy cash flow \\nposition, provide a strong foundation for continued growth into Q4 and beyond.\\n\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m------------------------------------------ Function Call ------------------------------------------\u001b[0m\n",
      "  \u001b[38;5;208mFunction Name:\u001b[0m `summarize_financial_report\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m------------------------------------------- Tool Result -------------------------------------------\u001b[0m\n",
      "  The Q3 2023 earnings report shows strong performance across all metrics with 20% revenue growth, 15% user engagement increase, 25% digital services growth, and improved retention rates of 92%.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m------------------------------------------ Function Call ------------------------------------------\u001b[0m\n",
      "  \u001b[38;5;208mFunction Name:\u001b[0m `send_discord_message\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m------------------------------------------- Tool Result -------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"status\": \"success\",\n",
      "  \"status_code\": 200,\n",
      "  \"channel\": \"#finance\",\n",
      "  \"message_preview\": \"The Q3 2023 earnings report shows strong performan...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m------------------------------------------ Function Call ------------------------------------------\u001b[0m\n",
      "  \u001b[38;5;208mFunction Name:\u001b[0m `send_discord_message\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------- Final Agent Response ---------------------------------------\u001b[0m\n",
      "  \u001b[38;5;208mFunction Name:\u001b[0m `send_discord_message\n",
      "  \u001b[38;5;208mFunction Arguments:\u001b[0m `{\n",
      "  \"message\": \"The Q3 2023 earnings report shows strong performance across all metrics with 20% revenue growth, 15% user engagement increase, 25% digital services growth, and improved retention rates of 92%.\",\n",
      "  \"channel_id\": \"#finance\"\n",
      "}`\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "max_iterations = 3\n",
    "while hasattr(response_message_part, \"function_call\") and max_iterations > 0:\n",
    "    tool_result = call_tool(response_message_part.function_call)\n",
    "    pretty_print.wrapped(tool_result, title=\"Tool Result\", indent=2)\n",
    "\n",
    "    # Add the tool result to the messages creating the following structure:\n",
    "    # - user prompt\n",
    "    # - tool call\n",
    "    # - tool result\n",
    "    # - tool call\n",
    "    # - tool result\n",
    "    # ...\n",
    "    function_response_part = types.Part.from_function_response(\n",
    "        name=response_message_part.function_call.name,\n",
    "        response={\"result\": tool_result},\n",
    "    )\n",
    "    messages.append(function_response_part)\n",
    "\n",
    "    # Ask the LLM to continue with the next step (which may involve calling another tool)\n",
    "    response = client.models.generate_content(\n",
    "        model=MODEL_ID,\n",
    "        contents=messages,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    response_message_part = response.candidates[0].content.parts[0]\n",
    "    pretty_print.function_call(response_message_part.function_call, only_name=True, title=\"Function Call\")\n",
    "\n",
    "    messages.append(response.candidates[0].content)\n",
    "\n",
    "    max_iterations -= 1\n",
    "\n",
    "pretty_print.function_call(response.candidates[0].content.parts[0].function_call, title=\"Final Agent Response\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running tools in a loop is powerful for multi-step tasks, but this naive approach has limitations. \n",
    "\n",
    "It doesn't provide explicit opportunities for the model to reason about tool outputs before deciding on the next action. The agent immediately moves to the next function call without pausing to think about what it learned or whether it should change strategy.\n",
    "\n",
    "This limitation leads us to more sophisticated patterns like **ReAct** (Reasoning and Acting), which explicitly interleaves reasoning steps with tool calls, allowing the agent to think through problems more deliberately. We will explore ReAct patterns in lessons 7 and 8."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
